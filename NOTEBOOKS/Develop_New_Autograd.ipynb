{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbf64715",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numba import njit\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "\n",
    "#from layerwise_ntk import compute_NTK_CNN\n",
    "import numpy as np\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a789bd00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_ntk(Ws: list, Ks: list, Xs: list, d_int: list, d_array: list, strides: list, padding: list, layers: list, d_activationt, device=\"cuda\",) -> list:\n",
    "    '''    \n",
    "    Inputs: \n",
    "    Ws: list, has length number of layers + any reshaping, contains dense layer weight tensors, detatched, and on device\n",
    "    Ks: list, has length number of layers + any reshaping, contains 2d convolutional layers weight tensors, detatched, and on device\n",
    "    Xs: list, has length number of layers + any reshaping, contains all intermediate outputs of each layer in the models\n",
    "    d_int: list, has the number of bias parameters in each dense layer in the models\n",
    "    d_array: list, has the value of which to sqrt and divide by in each layer, typically called the NTK normalization. else, its values are 1.\n",
    "    strides: list, has the value of stride in each convolutional layer, else 0\n",
    "    padding: list, has the value of padding in each convolutional layer, else 0\n",
    "    layers: list, is a list containing the pytorch layers in the model, and \"0\" as a placeholder for a reshaping layer\n",
    "    d_activationt, a function containing the derivative of the activation function used in all layers but the output layer, composed of pytorch functions\n",
    "    device: str, one of either 'cpu' or 'cuda'; must be the same as the model device location\n",
    "    \n",
    "    NOTE: all of the above lists should have the same length! See example\n",
    "    \n",
    "    OUTPUTS: list of torch.tensor objects, each the ntk 'component' for that layer. Given in backwards order, i.e. starting with the last layer. First weight, then bias.\n",
    "    \n",
    "    NOTE: to get the full ntk, simply sum over the layer dimension of the result: NTK = torch.sum(torch.stack(components),dim=(0))\n",
    "    \n",
    "    updated\n",
    "    '''\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T)\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Conv2d):\n",
    "                Ds_conv.append(d_activationt(layers[l](Xs[l].T)).reshape(n,-1).T)\n",
    "            else:\n",
    "                Ds_conv.append(np.array([[0.0]],dtype=np.float32))      \n",
    "        ####################################################################################################\n",
    "        S = torch.tensor([1.0],dtype=torch.float32).to(device) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                components.append(cross_pt_nonp(S,device)*cross_pt_nonp(Xs[l],device)/d_array[l])\n",
    "                if not(hasattr(layers[l], 'bias')) and not(getattr(layers[l], 'bias') is None):\n",
    "                    W = torch.ones((d_int[l],n),dtype=torch.float32).to(device) * S\n",
    "                    components.append(cross_pt_nonp(W,device).to(device)/d_array[l])\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                if len(S.shape) == 2: #this should only affect the very last layer, at which point, who cares.\n",
    "                    S = S[None,:,:]\n",
    "                    \n",
    "                dw = calc_dw(x=Xs[l].T.cpu().numpy(),w=Ks[l].cpu().numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                \n",
    "                W = torch.matmul(torch.from_numpy(dw).to(device),S.to(device))\n",
    "                \n",
    "                W = torch.diagonal(W,0,0,2)\n",
    "\n",
    "                components.append(cross_pt_nonp(W,device).to(device)/d_array[l])\n",
    "                \n",
    "                if not(hasattr(layers[l], 'bias')) and not(getattr(layers[l], 'bias') is None):\n",
    "                    N = Ks[l].shape[0]\n",
    "                    W = np.split(S.cpu().numpy(),N,axis=1)\n",
    "                    \n",
    "                    W = np.array(W)\n",
    "                    \n",
    "                    W = np.sum(W,axis=(1,2))\n",
    "                    \n",
    "                    components.append(torch.from_numpy(cross(W,)).to(device)/d_array[l])\n",
    "\n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                S = torch.matmul(S.T,Ws[l]).T / torch.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                dx = calc_dx(x=Xs[l].T.cpu().numpy(),w=Ks[l].cpu().numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                S = (torch.from_numpy(dx[None,:,:]).to(device) @ S) / torch.sqrt(d_array[l])\n",
    "                S = Ds_conv[l]*S\n",
    "            \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c84e31cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def d_activationt(x):\n",
    "    return torch.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76baf0ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(model, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(10,10,bias=False)\n",
    "\n",
    "        self.d2 = torch.nn.Linear(10,10,bias=False)\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(10,10,bias=False)\n",
    "        \n",
    "        self.d4 = torch.nn.Linear(10,1,bias=False)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        return x_4, x_3, x_2, x_1, x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f436f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "bafa46fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "SEED=0\n",
    "how_many=3\n",
    "\n",
    "import random\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cuda'\n",
    "\n",
    "mymodel = model()\n",
    "mymodel.apply(NTK_weights)\n",
    "mymodel.to(device)\n",
    "\n",
    "x_test = np.random.normal(0,1,(how_many,10)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "fbdca6bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hasattr(mymodel.d1,'bias') and not(getattr(mymodel.d1, 'bias') is None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4019ce31",
   "metadata": {},
   "source": [
    "# Calculate the Fisher Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "55439e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_pt_nonp(X,device='cuda'):\n",
    "    X = X.to(device)\n",
    "    return X.T.matmul(X)\n",
    "\n",
    "def notthatsimple(X,device='cuda'):\n",
    "    X = X.to(device)\n",
    "    return X.matmul(X.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "01875f49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def component_fisher(Ws: list, Ks: list, Xs: list, d_int: list, d_array: list, strides: list, padding: list, layers: list, d_activationt, device=\"cuda\",) -> list:\n",
    "    '''    \n",
    "    Inputs: \n",
    "    Ws: list, has length number of layers + any reshaping, contains dense layer weight tensors, detatched, and on device\n",
    "    Ks: list, has length number of layers + any reshaping, contains 2d convolutional layers weight tensors, detatched, and on device\n",
    "    Xs: list, has length number of layers + any reshaping, contains all intermediate outputs of each layer in the models\n",
    "    d_int: list, has the number of bias parameters in each dense layer in the models\n",
    "    d_array: list, has the value of which to sqrt and divide by in each layer, typically called the NTK normalization. else, its values are 1.\n",
    "    strides: list, has the value of stride in each convolutional layer, else 0\n",
    "    padding: list, has the value of padding in each convolutional layer, else 0\n",
    "    layers: list, is a list containing the pytorch layers in the model, and \"0\" as a placeholder for a reshaping layer\n",
    "    d_activationt, a function containing the derivative of the activation function used in all layers but the output layer, composed of pytorch functions\n",
    "    device: str, one of either 'cpu' or 'cuda'; must be the same as the model device location\n",
    "    \n",
    "    NOTE: all of the above lists should have the same length! See example\n",
    "    \n",
    "    OUTPUTS: list of torch.tensor objects, each the ntk 'component' for that layer. Given in backwards order, i.e. starting with the last layer. First weight, then bias.\n",
    "    \n",
    "    NOTE: to get the full ntk, simply sum over the layer dimension of the result: NTK = torch.sum(torch.stack(components),dim=(0))\n",
    "    \n",
    "    updated\n",
    "    '''\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T)\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ####################################################################################################\n",
    "        S = torch.tensor([1.0],dtype=torch.float32).to(device) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                print('S: ',S.shape)\n",
    "                print('Xs: ',Xs[l].shape)\n",
    "                components.append(S*Xs[l]/d_array[l])\n",
    "                print(components[-1].shape)\n",
    "                if (hasattr(layers[l], 'bias')) and not(getattr(layers[l], 'bias') is None):\n",
    "                    W = torch.ones((d_int[l],n),dtype=torch.float32).to(device) * S\n",
    "                    components.append(W.to(device)/d_array[l])\n",
    "            \n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                print(\"W: \",Ws[l].shape)\n",
    "                S = torch.matmul(S,Ws[l]).T / torch.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    print(\"D: \",Ds_dense[l].shape)\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S\n",
    "            \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "id": "edc7ae5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3])"
      ]
     },
     "execution_count": 215,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[-2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "c2f71fa4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = d_activationt(mymodel.d3(Xs[-2].T))\n",
    "D.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "6cb40d4b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 10])"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws[-1].shape #first index is the output index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f49ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dw_dw(X):\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "66d8e2be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.matmul((Ws[-1] * D), (Xs[-2])).shape # N x P = 3 x 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "fb152a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.to('cuda')\n",
    "x_4, x_3, x_2, x_1, x_0 = mymodel(x_test)\n",
    "\n",
    "#These need to be numpy\n",
    "Ws = []\n",
    "Ws.append(mymodel.d1.weight.detach())\n",
    "Ws.append(mymodel.d2.weight.detach())\n",
    "Ws.append(mymodel.d3.weight.detach())\n",
    "Ws.append(mymodel.d4.weight.detach())\n",
    "\n",
    "#Kernel Matrices, Need to be numpy\n",
    "Ks = []\n",
    "Ks.append(mymodel.d1.weight.detach())\n",
    "Ks.append(mymodel.d2.weight.detach())\n",
    "Ks.append(mymodel.d3.weight.detach())\n",
    "Ks.append(mymodel.d4.weight.detach())\n",
    "\n",
    "\n",
    "Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "Xs.append(x_0.T.detach())\n",
    "Xs.append(x_1.T.detach())\n",
    "Xs.append(x_2.T.detach())\n",
    "Xs.append(x_3.T.detach())\n",
    "#Xs.append(x_4.T.detach())\n",
    "\n",
    "#This is used to create arrays-- needs to be integer list to play nice with compilers\n",
    "ds_int = []\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "\n",
    "ds_array = [] #this is for the NTK formulation, \n",
    "#ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #first element is a spacer, could be anything.\n",
    "\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #first element is a spacer, could be anything.\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #The rest, even if you dont use NTK formulation, would be 1\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "\n",
    "filters = []\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "\n",
    "\n",
    "padding = []\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "\n",
    "\n",
    "strides = []\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "\n",
    "\n",
    "layers=[mymodel.d1,\n",
    "        mymodel.d2,\n",
    "        mymodel.d3,\n",
    "        mymodel.d4,\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "57e6f9ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "S:  torch.Size([1])\n",
      "Xs:  torch.Size([10, 3])\n",
      "torch.Size([10, 3])\n",
      "W:  torch.Size([1, 10])\n",
      "D:  torch.Size([10, 3])\n",
      "S:  torch.Size([10, 3])\n",
      "Xs:  torch.Size([10, 3])\n",
      "torch.Size([10, 3])\n",
      "W:  torch.Size([10, 10])\n",
      "D:  torch.Size([10, 3])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-209-9971b2f42a9e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcomponent_fisher\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_int\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mds_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0md_activationt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-207-bfaebb1157b6>\u001b[0m in \u001b[0;36mcomponent_fisher\u001b[1;34m(Ws, Ks, Xs, d_int, d_array, strides, padding, layers, d_activationt, device)\u001b[0m\n\u001b[0;32m     60\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#this exludes the reshaping layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m                     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"D: \"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mDs_dense\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDs_dense\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m \u001b[1;31m#and when the reshaping layer occurs we need to apply this instead\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m                     \u001b[0mS\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mDs_conv\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0ml\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mS\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: The size of tensor a (3) must match the size of tensor b (10) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "fc = component_fisher(Ws, Ks, Xs, ds_int, ds_array, strides, padding, layers, d_activationt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "54d7a243",
   "metadata": {},
   "outputs": [],
   "source": [
    "#earliest layers come last\n",
    "I_fc_00 = fc[-1]@fc[-1].T\n",
    "I_fc_01 = fc[-1]@fc[-2].T\n",
    "I_fc_02 = fc[-1]@fc[-3].T\n",
    "I_fc_03 = fc[-1]@fc[-4].T\n",
    "\n",
    "I_fc_10 = fc[-2]@fc[-1].T\n",
    "I_fc_11 = fc[-2]@fc[-2].T\n",
    "I_fc_12 = fc[-2]@fc[-3].T\n",
    "I_fc_13 = fc[-2]@fc[-4].T\n",
    "\n",
    "I_fc_20 = fc[-3]@fc[-1].T\n",
    "I_fc_21 = fc[-3]@fc[-2].T\n",
    "I_fc_22 = fc[-3]@fc[-3].T\n",
    "I_fc_23 = fc[-3]@fc[-4].T\n",
    "\n",
    "I_fc_30 = fc[-4]@fc[-1].T\n",
    "I_fc_31 = fc[-4]@fc[-2].T\n",
    "I_fc_32 = fc[-4]@fc[-3].T\n",
    "I_fc_33 = fc[-4]@fc[-4].T\n",
    "\n",
    "Ifc_pieces_0 = torch.cat([I_fc_00,I_fc_01,I_fc_02,I_fc_03],axis=1) #100, 341\n",
    "Ifc_pieces_1 = torch.cat([I_fc_10,I_fc_11,I_fc_12,I_fc_13],axis=1) #100, 341\n",
    "Ifc_pieces_2 = torch.cat([I_fc_20,I_fc_21,I_fc_22,I_fc_23],axis=1) #100, 341\n",
    "Ifc_pieces_3 = torch.cat([I_fc_30,I_fc_31,I_fc_32,I_fc_33],axis=1) #100, 341\n",
    "\n",
    "Ifc_pieces = torch.cat([Ifc_pieces_0,Ifc_pieces_1,Ifc_pieces_2,Ifc_pieces_3],axis=0) #341, 341\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "248fd635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([40, 40])"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ifc_pieces.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a397ce2a",
   "metadata": {},
   "source": [
    "# Develop Autograd because we need to check if these preliminary matrices are correct anyways"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "6f56fad8",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mymodel(x_test)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "be820acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "f644e9b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the future we would iterate over layers instead of like this...\n",
    "layer_components_w1 = [] \n",
    "layer_components_w2 = []\n",
    "layer_components_w3 = []\n",
    "layer_components_w4 = []\n",
    "\n",
    "layer_components_b1 = []\n",
    "layer_components_b2 = []\n",
    "layer_components_b3 = []\n",
    "layer_components_b4 = []\n",
    "\n",
    "for i in range(len(y)):#range(len(y)):\n",
    "    mymodel.zero_grad()\n",
    "    y[i,0].backward(retain_graph=True)\n",
    "    #Get the tensors\n",
    "\n",
    "    #reshape and append. deep copy neccessary or else they are the same objects\n",
    "    layer_components_w1.append(mymodel.d1.weight.grad.detach().reshape(-1).clone())\n",
    "    layer_components_w2.append(mymodel.d2.weight.grad.detach().reshape(-1).clone())\n",
    "    layer_components_w3.append(mymodel.d3.weight.grad.detach().reshape(-1).clone())\n",
    "    layer_components_w4.append(mymodel.d4.weight.grad.detach().reshape(-1).clone())\n",
    "    \n",
    "J_w1 = torch.stack(layer_components_w1).T\n",
    "J_w2 = torch.stack(layer_components_w2).T \n",
    "J_w3 = torch.stack(layer_components_w3).T\n",
    "J_w4 = torch.stack(layer_components_w4).T \n",
    "\n",
    "J = torch.cat([J_w1,J_w2,J_w3,J_w4],dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "f1dac8c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK = (J.T@J) #N x N matrix\n",
    "NTK.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "8465b736",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.7999e-10, 4.1165e-03, 7.8675e+00], device='cuda:0')"
      ]
     },
     "execution_count": 271,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvalsh(NTK)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "df710fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = (J@J.T) # P x P matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "32505253",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3.5996e-07, 4.1161e-03, 7.8675e+00], device='cuda:0')"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvalsh(I)[-3::] #these are, to machine precision.... which I guess is like 10e-6;\n",
    "#so I guess that has implications for out NTK eigenvalue anaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "9aa0d57d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 274,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J_w1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "f7cb2f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "I_00 = J_w1@J_w1.T\n",
    "I_01 = J_w1@J_w1.T\n",
    "I_02 = J_w1@J_w1.T\n",
    "I_03 = J_w1@J_w1.T\n",
    "\n",
    "I_10 = J_w1@J_w1.T\n",
    "I_11 = J_w1@J_w1.T\n",
    "I_12 = J_w1@J_w1.T\n",
    "I_13 = J_w1@J_w1.T\n",
    "\n",
    "I_20 = J_w1@J_w1.T\n",
    "I_21 = J_w1@J_w1.T\n",
    "I_22 = J_w1@J_w1.T\n",
    "I_23 = J_w1@J_w1.T\n",
    "\n",
    "I_30 = J_w1@J_w1.T\n",
    "I_31 = J_w1@J_w1.T\n",
    "I_32 = J_w1@J_w1.T\n",
    "I_33 = J_w1@J_w1.T\n",
    "\n",
    "Ifc_pieces_0 = torch.cat([I_fc_00,I_fc_01,I_fc_02,I_fc_03],axis=1) #100, 341\n",
    "Ifc_pieces_1 = torch.cat([I_fc_10,I_fc_11,I_fc_12,I_fc_13],axis=1) #100, 341\n",
    "Ifc_pieces_2 = torch.cat([I_fc_20,I_fc_21,I_fc_22,I_fc_23],axis=1) #100, 341\n",
    "Ifc_pieces_3 = torch.cat([I_fc_30,I_fc_31,I_fc_32,I_fc_33],axis=1) #100, 341\n",
    "\n",
    "Ifc_pieces = torch.cat([Ifc_pieces_0,Ifc_pieces_1,Ifc_pieces_2,Ifc_pieces_3],axis=0) #341, 341\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "e2100102",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        ...,\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True],\n",
       "        [True, True, True,  ..., True, True, True]], device='cuda:0')"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I == I_pieces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67fdc358",
   "metadata": {},
   "outputs": [],
   "source": [
    "I = J[0:100,0:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "270e244d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1.2020423e-03  5.4884329e-04  7.9924171e-04 ...  4.5533446e-03\n",
      "  -2.4962872e-03 -5.6376527e-03]\n",
      " [ 5.4884329e-04  2.9127533e-03  1.6404245e-03 ...  4.2535797e-02\n",
      "  -2.1792766e-02 -5.3483039e-02]\n",
      " [ 7.9924171e-04  1.6404245e-03  1.1425368e-03 ...  2.2411257e-02\n",
      "  -1.1555082e-02 -2.8140074e-02]\n",
      " ...\n",
      " [ 4.5533446e-03  4.2535797e-02  2.2411257e-02 ...  6.3206965e-01\n",
      "  -3.2331926e-01 -7.9501843e-01]\n",
      " [-2.4962872e-03 -2.1792766e-02 -1.1555082e-02 ... -3.2331926e-01\n",
      "   1.6540968e-01  4.0665877e-01]\n",
      " [-5.6376527e-03 -5.3483039e-02 -2.8140074e-02 ... -7.9501843e-01\n",
      "   4.0665877e-01  9.9998254e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(I.detach().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "bb4e500c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 3])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_components_w1.shape #[P x N]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "56b4f93d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = layer_components_w1 @ layer_components_w1.T  #this should be left in the torch tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "13b99c5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "dd07ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 10])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fisher_components[-5].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c59f1e8",
   "metadata": {},
   "source": [
    "# what about improvements to torch.autograd.jacobian"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "e87ed190",
   "metadata": {},
   "outputs": [],
   "source": [
    "y2 = mymodel(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8aa2219f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 10])"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y2[-1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "88a8a45c",
   "metadata": {},
   "outputs": [],
   "source": [
    "J1 = torch.autograd.functional.jacobian(mymodel,y2[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "c30df688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]],\n",
       "\n",
       "\n",
       "        [[[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]],\n",
       "\n",
       "         [[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "          [0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]]], device='cuda:0')"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "J1[4]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ec08268",
   "metadata": {},
   "source": [
    "# Layerwise Autograd Method for arbitary pytorch models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "f551e4eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class model2(torch.nn.Module):\n",
    "    def __init__(self,):\n",
    "        super(model2, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(10,10,bias=False)\n",
    "\n",
    "        self.d2 = torch.nn.Linear(10,10,bias=False)\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(10,10,bias=False)\n",
    "        \n",
    "        self.d4 = torch.nn.Linear(10,1,bias=False)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        return x_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "2930b899",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([10, 10])\n",
      "torch.Size([1, 10])\n"
     ]
    }
   ],
   "source": [
    "mymodel2 = model2()\n",
    "mymodel2.apply(NTK_weights)\n",
    "mymodel2.to(device)\n",
    "\n",
    "x_test2 = np.random.normal(0,1,(how_many,10)).astype(np.float32) #n c_in, h, w\n",
    "x_test2 = torch.from_numpy(x_test2)\n",
    "x_test2 = x_test2.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "id": "7e554c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = mymodel2(x_test2)[:,0] #defined to only work for networks that terminate to single neuron, so this is okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ee8e402",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autograd_components_NTK(model: torch.nn.Module, y :torch.tensor):\n",
    "    \n",
    "    NTKs = {}\n",
    "    \n",
    "    if len(y.shape) > 1:\n",
    "        raise ValueError('y must be 1-D, but its shape is: {}'.format(y.shape))\n",
    "    \n",
    "    params_that_need_grad = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "            #first set all gradients to not calculate, time saver\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "\n",
    "    #how do we parallelize this operation across multiple gpus or something? that be sweet.\n",
    "    for i,z in enumerate(model.named_parameters()):\n",
    "        if not(params_that_need_grad[i]): #if it didnt need a grad, we can skip it.\n",
    "            continue\n",
    "        name, param = z\n",
    "        param.requires_grad = True #we only care about this tensors gradients in the loop\n",
    "        this_grad=[]\n",
    "        for i in range(len(y)): #first dimension must be the batch dimension\n",
    "            model.zero_grad()\n",
    "            y[i].backward(create_graph=True)\n",
    "            this_grad.append(param.grad.detach().reshape(-1).clone())\n",
    "\n",
    "        J_layer = torch.stack(this_grad) # [N x P matrix] #this will go against our notation, but I'm not adding\n",
    "\n",
    "        NTKs[name] = J_layer @ J_layer.T # An extra transpose operation to my code for us to feel better\n",
    "\n",
    "        param.requires_grad = False\n",
    "     \n",
    "    #reset the model object to be how we started this function\n",
    "    for i,param in enumerate(model.parameters()):\n",
    "        if params_that_need_grad[i]:\n",
    "            param.requires_grad = True #\n",
    "\n",
    "    return NTKs\n",
    "\n",
    "def autograd_components_Fisher(model: torch.nn.Module, y :torch.tensor):\n",
    "    \n",
    "    fishers = {}\n",
    "    \n",
    "    if len(y.shape) > 1:\n",
    "        raise ValueError('y must be 1-D, but its shape is: {}'.format(y.shape))\n",
    "    \n",
    "    params_that_need_grad = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "            #first set all gradients to not calculate, time saver\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "\n",
    "    #how do we parallelize this operation across multiple gpus or something? that be sweet.\n",
    "    for i,z in enumerate(model.named_parameters()):\n",
    "        if not(params_that_need_grad[i]): #if it didnt need a grad, we can skip it.\n",
    "            continue\n",
    "        name, param = z\n",
    "        param.requires_grad = True #we only care about this tensors gradients in the loop\n",
    "        this_grad=[]\n",
    "        for i in range(len(y)): #first dimension must be the batch dimension\n",
    "            model.zero_grad()\n",
    "            y[i].backward(create_graph=True)\n",
    "            this_grad.append(param.grad.detach().reshape(-1).clone())\n",
    "\n",
    "        J_layer = torch.stack(this_grad) # [N x P matrix] #this will go against our notation, but I'm not adding\n",
    "\n",
    "        fishers[name] = J_layer.T @ J_layer # An extra transpose operation to my code for us to feel better\n",
    "\n",
    "        param.requires_grad = False\n",
    "     \n",
    "    #reset the model object to be how we started this function\n",
    "    for i,param in enumerate(model.parameters()):\n",
    "        if params_that_need_grad[i]:\n",
    "            param.requires_grad = True #\n",
    "\n",
    "    return fishers \n",
    "\n",
    "def reconstruct_full_fisher_from_components(fisher):\n",
    "    raise ValueError('Not Implemented Yet')\n",
    "    #given the dictionary of fisher information matrices, we can \n",
    "    #combine them to get the full fisher information matrix.\n",
    "    return\n",
    "\n",
    "def autograd_components_Jacobian(model: torch.nn.Module, y :torch.tensor):\n",
    "    \n",
    "    Jacobians = {}\n",
    "    \n",
    "    if len(y.shape) > 1:\n",
    "        raise ValueError('y must be 1-D, but its shape is: {}'.format(y.shape))\n",
    "    \n",
    "    params_that_need_grad = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "            #first set all gradients to not calculate, time saver\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "\n",
    "    #how do we parallelize this operation across multiple gpus or something? that be sweet.\n",
    "    for i,z in enumerate(model.named_parameters()):\n",
    "        if not(params_that_need_grad[i]): #if it didnt need a grad, we can skip it.\n",
    "            continue\n",
    "        name, param = z\n",
    "        param.requires_grad = True #we only care about this tensors gradients in the loop\n",
    "        this_grad=[]\n",
    "        for i in range(len(y)): #first dimension must be the batch dimension\n",
    "            model.zero_grad()\n",
    "            y[i].backward(create_graph=True)\n",
    "            this_grad.append(param.grad.detach().reshape(-1).clone())\n",
    "\n",
    "        J_layer = torch.stack(this_grad) # [N x P matrix] #this will go against our notation, but I'm not adding\n",
    "\n",
    "        Jacobians[name] = J_layer # An extra transpose operation to my code for us to feel better\n",
    "\n",
    "        param.requires_grad = False\n",
    "     \n",
    "    #reset the model object to be how we started this function\n",
    "    for i,param in enumerate(model.parameters()):\n",
    "        if params_that_need_grad[i]:\n",
    "            param.requires_grad = True #\n",
    "\n",
    "    return Jacobians\n",
    "\n",
    "\n",
    "        \n",
    "def autograd_NTK(model: torch.nn.Module, y :torch.tensor):\n",
    "    \n",
    "    NTK = False\n",
    "    \n",
    "    if len(y.shape) > 1:\n",
    "        raise ValueError('y must be 1-D, but its shape is: {}'.format(y.shape))\n",
    "    \n",
    "    params_that_need_grad = []\n",
    "    for param in model.parameters():\n",
    "        if param.requires_grad:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "            #first set all gradients to not calculate, time saver\n",
    "            param.requires_grad = False\n",
    "        else:\n",
    "            params_that_need_grad.append(param.requires_grad)\n",
    "\n",
    "    #how do we parallelize this operation across multiple gpus or something? that be sweet.\n",
    "    for i,z in enumerate(model.named_parameters()):\n",
    "        if not(params_that_need_grad[i]): #if it didnt need a grad, we can skip it.\n",
    "            continue\n",
    "        name, param = z\n",
    "        param.requires_grad = True #we only care about this tensors gradients in the loop\n",
    "        this_grad=[]\n",
    "        for i in range(len(y)): #first dimension must be the batch dimension\n",
    "            model.zero_grad()\n",
    "            y[i].backward(create_graph=True)\n",
    "            this_grad.append(param.grad.detach().reshape(-1).clone())\n",
    "\n",
    "        J_layer = torch.stack(this_grad) # [N x P matrix] #this will go against our notation, but I'm not adding\n",
    "\n",
    "        if (type(NTK) is bool) and not(NTK):\n",
    "            NTK = J_layer @ J_layer.T # An extra transpose operation to my code for us to feel better\n",
    "        else:\n",
    "            NTK += J_layer @ J_layer.T\n",
    "\n",
    "        param.requires_grad = False\n",
    "     \n",
    "    #reset the model object to be how we started this function\n",
    "    for i,param in enumerate(model.parameters()):\n",
    "        if params_that_need_grad[i]:\n",
    "            param.requires_grad = True #\n",
    "\n",
    "    return NTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b699c01",
   "metadata": {},
   "source": [
    "# What about something like this?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8612ba44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2225153"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(dict((p.data_ptr(), p.numel()) for p in vgg11.parameters()).values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a2e727b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MobileNetV2(\n",
       "  (features): Sequential(\n",
       "    (0): ConvBNActivation(\n",
       "      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "    (1): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (2): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\n",
       "          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (3): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (4): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\n",
       "          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (5): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (6): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (7): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\n",
       "          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (8): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (9): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (10): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (11): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\n",
       "          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (12): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (13): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (14): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\n",
       "          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (15): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (16): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (17): InvertedResidual(\n",
       "      (conv): Sequential(\n",
       "        (0): ConvBNActivation(\n",
       "          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (1): ConvBNActivation(\n",
       "          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\n",
       "          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU6(inplace=True)\n",
       "        )\n",
       "        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (18): ConvBNActivation(\n",
       "      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU6(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.2, inplace=False)\n",
       "    (1): Linear(in_features=1280, out_features=1, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torchvision.models as models\n",
    "vgg11 = models.mobilenet_v2(num_classes=1)\n",
    "vgg11.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "061ea7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train3 = torch.empty(100,3,32,32).normal_(0,1).to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0132487b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = vgg11(x_train3)[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f679aa72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "501.2134418487549\n"
     ]
    }
   ],
   "source": [
    "now=time.time()\n",
    "NTK = autograd_NTK(vgg11, y)\n",
    "print(time.time()-now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8fbdfb11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61697a2e",
   "metadata": {},
   "source": [
    "# $$I = ( \\nabla f_\\theta(x)) ( \\nabla f_\\theta(x)^\\top) $$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
