{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f3101ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from layerwise_ntk import compute_NTK_CNN\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9eeee325",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_ntk import calculate_NTK\n",
    "from easy_ntk import get_ntk_n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb984e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "how_many = 1000\n",
    "width = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "daee6935",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def d_activationt(x):\n",
    "    return torch.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ec4ef9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d6023cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dumb_small(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(1,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d3 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d4 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d5 = torch.nn.Linear(width*28*28,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = x_4.reshape(how_many,-1)\n",
    "        x_6 = self.d5(x_5)\n",
    "        return x_6 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60b9b31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 3, 3])\n",
      "torch.Size([8, 8, 3, 3])\n",
      "torch.Size([8, 8, 3, 3])\n",
      "torch.Size([8, 8, 3, 3])\n",
      "torch.Size([1, 6272])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model_2 = dumb_small()\n",
    "model_2.apply(NTK_weights)\n",
    "x_test = np.random.normal(0,1,(how_many,1,28,28)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a43b5690",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dumb_small(\n",
       "  (d1): Conv2d(1, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d2): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d3): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d4): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (d5): Linear(in_features=6272, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_2.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c9b28c08",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 23.37 GiB (GPU 0; 11.91 GiB total capacity; 102.88 MiB already allocated; 10.92 GiB free; 118.00 MiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_19693/2059637469.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mNTK_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcalculate_NTK\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/qfs/people/enge625/jupyter_test/NOTEBOOKS/benchmark_ntk/ntk.py\u001b[0m in \u001b[0;36mcalculate_NTK\u001b[0;34m(model, x, device, MODE)\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m     \u001b[0mJs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjacobian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_ntk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvectorize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0mJs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mJs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#needs to be mutable, tuples aren't mutable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/perfect/lib/python3.7/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mjacobian\u001b[0;34m(func, inputs, create_graph, strict, vectorize)\u001b[0m\n\u001b[1;32m    539\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    540\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 541\u001b[0;31m         \u001b[0mjacobians_of_flat_output\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_vmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvjp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_outputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    543\u001b[0m         \u001b[0;31m# Step 3: The returned jacobian is one big tensor per input. In this step,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/perfect/lib/python3.7/site-packages/torch/_vmap_internals.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0mbatched_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_batched_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m             \u001b[0mbatched_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatched_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m             \u001b[0m_validate_outputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0m_unwrap_batched\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatched_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout_dims\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvmap_level\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/perfect/lib/python3.7/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36mvjp\u001b[0;34m(grad_output)\u001b[0m\n\u001b[1;32m    532\u001b[0m         \u001b[0;31m# Step 2: Call vmap + autograd.grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    533\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mvjp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrad_output\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 534\u001b[0;31m             \u001b[0mvj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_autograd_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflat_outputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_output\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    535\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mel_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvj_el\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    536\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mvj_el\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/perfect/lib/python3.7/site-packages/torch/autograd/functional.py\u001b[0m in \u001b[0;36m_autograd_grad\u001b[0;34m(outputs, inputs, grad_outputs, create_graph, retain_graph)\u001b[0m\n\u001b[1;32m    146\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    147\u001b[0m         return torch.autograd.grad(new_outputs, inputs, new_grad_outputs, allow_unused=True,\n\u001b[0;32m--> 148\u001b[0;31m                                    create_graph=create_graph, retain_graph=retain_graph)\n\u001b[0m\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_fill_in_zeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrefs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.conda/envs/perfect/lib/python3.7/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused)\u001b[0m\n\u001b[1;32m    223\u001b[0m     return Variable._execution_engine.run_backward(\n\u001b[1;32m    224\u001b[0m         \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_outputs_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m         inputs, allow_unused, accumulate_grad=False)\n\u001b[0m\u001b[1;32m    226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 23.37 GiB (GPU 0; 11.91 GiB total capacity; 102.88 MiB already allocated; 10.92 GiB free; 118.00 MiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "NTK_1 = calculate_NTK(model_2, x_test, device='cuda')\n",
    "time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9bceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "calculate_NTK(model_2, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c2f340a",
   "metadata": {},
   "source": [
    "# now for an autograd method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1196e1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "fake_targets = torch.tensor(np.ones(how_many))\n",
    "dataset = TensorDataset(x_test, fake_targets)\n",
    "xloader = DataLoader(dataset, batch_size=how_many, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e81061e",
   "metadata": {},
   "outputs": [],
   "source": [
    "now = time.time()\n",
    "NTK_2 = get_ntk_n(xloader,model_2)\n",
    "time.time() - now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc97a55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "get_ntk_n(xloader,model_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba528bee",
   "metadata": {},
   "source": [
    "# By the way, these are consistent with each other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01db2305",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.allclose(NTK_1,NTK_2,1e-4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
