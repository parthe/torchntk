{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae2a2629",
   "metadata": {},
   "source": [
    "# Note to self, if the computation could be done in PyTorch, then maybe the entire thing could be formulated as a a function of the model (which it is) and then the computations could be done on GPU using PyTorch tensors. \n",
    "\n",
    "# Need to see if the PyTorch multiplies recgonize the symmetry thing\n",
    "\n",
    "# What is the significance of each Layer's NTK component?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f5b45374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "#from ..easy_ntk import calculate_NTK\n",
    "from einops import rearrange\n",
    "\n",
    "import time\n",
    "\n",
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "from numba import njit\n",
    "from numba.typed import List\n",
    "\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c94b0456",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy CNN function-- checked that it agrees with Tensorflow.\n",
    "#need to make sure it agrees with PyTorch.\n",
    "class Conv2d():\n",
    "    def __init__(self,F,strides=1,padding=0):\n",
    "        '''\n",
    "        PYTORCH IMPLEMENTATION!!!\n",
    "        \n",
    "        #given an input of x = [batches, length, channels]\n",
    "        \n",
    "        #F an input of = [channels_out, channels, kernel_size]\n",
    "        \n",
    "        #B an input of [channels_out]\n",
    "        \n",
    "        #ouputs a shape: [batches, new_length, channels_out]\n",
    "        \n",
    "        #   1. Flattens the filter to a 2-D matrix with shape\n",
    "        #      `[filter_height * filter_width * in_channels, output_channels]`.\n",
    "        #   2. Extracts image patches from the input tensor to form a *virtual*\n",
    "        #      tensor of shape `[batch, out_height, out_width, \n",
    "        #      filter_height * filter_width * in_channels]`. batch, new_length, kernel_size * in_channels\n",
    "        #   3. For each patch, right-multiplies the filter matrix and the image patch\n",
    "        #      vector.\n",
    "        '''\n",
    "        if padding < 0:\n",
    "            raise ValueError('Padding must be a non-negative int')\n",
    "        \n",
    "        self.out_filters = F.shape[0]\n",
    "        self.in_filters = F.shape[1]\n",
    "        self.kernel_height = F.shape[2]\n",
    "        self.kernel_width = F.shape[3]\n",
    "        self.F = F.T #filters array, now is [width, height, channels_in, channels_out]\n",
    "        #self.B = B #bias array\n",
    "        self.strides = strides\n",
    "        self.padding = padding\n",
    "        \n",
    "        self.F = np.reshape(self.F,(-1,self.out_filters))\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        batches, channels_in, height, width  = np.shape(x)\n",
    "        \n",
    "        if self.padding != 0:\n",
    "            x = np.pad(x,((0,0),(0,0),(self.padding,self.padding),(self.padding,self.padding)),mode='constant',constant_values=0.0)\n",
    "    \n",
    "        new_height = int(((height + 2*self.padding - (self.kernel_height))/self.strides) + 1)\n",
    "        new_width = int(((width + 2*self.padding - (self.kernel_width))/self.strides) + 1)\n",
    "        \n",
    "        dumb_array = np.zeros((batches, new_height, new_width, self.kernel_width * self.kernel_height * channels_in),dtype=np.float32)\n",
    "        \n",
    "        if self.strides == 1:\n",
    "            for i in range(new_height):\n",
    "                for j in range(new_width):\n",
    "                    dumb_array[:,i,j,:] = np.reshape(x[:,:,self.strides*i:self.strides*i+self.kernel_height, self.strides*j:self.strides*j+self.kernel_width],(batches, self.kernel_width * self.kernel_height * channels_in),order='F')\n",
    "        \n",
    "        assert self.strides==1\n",
    "        #We Will have to devote time to understanding how PyTorch uses padding;\n",
    "        #until then can't use strides > 1\n",
    "\n",
    "#         if self.strides > 1:\n",
    "#             if length % self.strides == 1:\n",
    "#                 for i in range(new_length):\n",
    "#                     dumb_array[:,i,:] = np.reshape(x[:,self.strides*(i):self.strides*i+self.kernel_size,:],(batches, self.kernel_width*self.kernel_height*channels))\n",
    "#             if length % self.strides == 0:\n",
    "#                 for i in range(new_length):\n",
    "#                     dumb_array[:,i,:] = np.reshape(x[:,1+self.strides*i:1+self.strides*i+self.kernel_size,:],(batches, self.kernel_width*self.kernel_height*channels))\n",
    "\n",
    "        output_array = dumb_array @ self.F\n",
    "        \n",
    "        #The values are correct, but we need to figure out how to make numpy do this operation. neither\n",
    "        #order F or C gives us the correct method. Pytorch must use two resahpes?\n",
    "        \n",
    "        #output_array = np.reshape(output_array,(batches,self.out_filters,new_height,new_width),order='C')\n",
    "        \n",
    "        #Einops works alright though.\n",
    "        output_array = rearrange(output_array,'b h w f -> b f h w')\n",
    "        \n",
    "        self.dumb_array = dumb_array # I think this is important\n",
    "\n",
    "        return output_array #+ self.B[None,None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7a93d8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "def _del_nested_attr(obj, names):\n",
    "    \"\"\"\n",
    "    Deletes the attribute specified by the given list of names.\n",
    "    For example, to delete the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'])\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        delattr(obj, names[0])\n",
    "    else:\n",
    "        _del_nested_attr(getattr(obj, names[0]), names[1:])\n",
    "\n",
    "def _set_nested_attr(obj, names, value):\n",
    "    \"\"\"\n",
    "    Set the attribute specified by the given list of names to value.\n",
    "    For example, to set the attribute obj.conv.weight,\n",
    "    use _del_nested_attr(obj, ['conv', 'weight'], value)\n",
    "    \"\"\"\n",
    "    if len(names) == 1:\n",
    "        setattr(obj, names[0], value)\n",
    "    else:\n",
    "        _set_nested_attr(getattr(obj, names[0]), names[1:], value)\n",
    "\n",
    "def extract_weights(mod):\n",
    "    \"\"\"\n",
    "    This function removes all the Parameters from the model and\n",
    "    return them as a tuple as well as their original attribute names.\n",
    "    The weights must be re-loaded with `load_weights` before the model\n",
    "    can be used again.\n",
    "    Note that this function modifies the model in place and after this\n",
    "    call, mod.parameters() will be empty.\n",
    "    \"\"\"\n",
    "    orig_params = tuple(mod.parameters())\n",
    "    # Remove all the parameters in the model\n",
    "    names = []\n",
    "    for name, p in list(mod.named_parameters()):\n",
    "        _del_nested_attr(mod, name.split(\".\"))\n",
    "        names.append(name)\n",
    "\n",
    "    # Make params regular Tensors instead of nn.Parameter\n",
    "    params = tuple(p.detach().requires_grad_() for p in orig_params)\n",
    "    return params, names\n",
    "\n",
    "def load_weights(mod, names, params):\n",
    "    \"\"\"\n",
    "    Reload a set of weights so that `mod` can be used again to perform a forward pass.\n",
    "    Note that the `params` are regular Tensors (that can have history) and so are left\n",
    "    as Tensors. This means that mod.parameters() will still be empty after this call.\n",
    "    \"\"\"\n",
    "    for name, p in zip(names, params):\n",
    "        _set_nested_attr(mod, name.split(\".\"), p)\n",
    "        \n",
    "def calculate_NTK(model,x,device='cpu',MODE='samples'):\n",
    "    \"\"\"\n",
    "    INPUTS:\n",
    "        model: torch.nn.Module \n",
    "        x: torch.Tensor\n",
    "        device: 'cpu',\n",
    "        MODE: 'minima'\n",
    "    \n",
    "    OUTPUTS:\n",
    "        NTK: torch.Tensor\n",
    "    \n",
    "    Calculates the NTK for a model, p_dict a state dictionary, and x, a single tensor fed into the model\n",
    "    \n",
    "    The NTK is the grammian of the Jacobian of the model output to w.r.t. the weights of the model\n",
    "    \n",
    "    This function will output the NTK such that the minima matrix size is used. If the Jacobian is an NxM\n",
    "    matrix, then the NTK is formulated so that if N < M; NTK is NxN. If M<N, then NTK is MxM.\n",
    "    \n",
    "    #EXAMPLE USAGE:\n",
    "    device='cpu'\n",
    "    model = MODEL() #a torch.nn.Module object \n",
    "    model.to(device)\n",
    "    state_dict = model.state_dict()\n",
    "\n",
    "    x_test = np.ones((100,1,28,28),dtype=np.float32)\n",
    "    x_test = torch.from_numpy(x_test)\n",
    "\n",
    "    NTK = calculate_NTK(model,x_test)\n",
    "    \"\"\"\n",
    "    if not(MODE in ['minima','samples','params']):\n",
    "        raise ValueError(\"MODE must be one of 'minima','samples','params'\")\n",
    "    \n",
    "    x = x.to(device)\n",
    "    x.requires_grad=False\n",
    "    N = x.shape[0]\n",
    "    M = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "    \n",
    "    #We need to create a clone of the model or else we make it unusable as part of the trickery \n",
    "    #to get pytorch to do what we want. Unforutantely, this exlcludes super big models. but, eh.\n",
    "    model_clone = copy.deepcopy(model)\n",
    "    \n",
    "    params, names = extract_weights(model_clone)\n",
    "    def model_ntk(*args,model=model_clone, names=names):\n",
    "        params = tuple(args)\n",
    "        load_weights(model, names, params)\n",
    "        return model(x)\n",
    "    \n",
    "    Js = torch.autograd.functional.jacobian(model_ntk, tuple(params), create_graph=False, vectorize=True)\n",
    "    \n",
    "    Js = list(Js)\n",
    "    #Js = [element for tupl in Js for element in tupl]\n",
    "    #collapse the tensors\n",
    "    for i,tensor in enumerate(Js):\n",
    "        Js[i] = tensor.reshape(N,-1)\n",
    "    \n",
    "    J = torch.cat(Js,axis=1)\n",
    "    \n",
    "    if MODE=='minima':\n",
    "        if N < M: #if datasize points is less than number of parameters:\n",
    "            NTK = torch.matmul(J,J.T)\n",
    "\n",
    "        if N >= M:#if number of parameters is less than datasize:\n",
    "            NTK = torch.matmul(J.T,J)\n",
    "    elif MODE=='samples':\n",
    "        NTK = torch.matmul(J,J.T)\n",
    "    elif MODE=='params':\n",
    "        NTK = torch.matmul(J.T,J)\n",
    "    \n",
    "    return NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af6781cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_dw(x,w,b,pad,stride,H_,W_):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of conv(x,w) with respect to w\n",
    "    \"\"\"\n",
    "    \n",
    "    dx, dw, db = None, None, None\n",
    "\n",
    "    # Récupération des variables\n",
    "    #x, w, b, conv_param = cache\n",
    "    #pad = conv_param['pad']\n",
    "    #stride = conv_param['stride']\n",
    "    \n",
    "    # Dimensions\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape\n",
    "    #_, _, H_, W_ = dout.shape\n",
    "    \n",
    "    # db - dout (N, F, H', W')\n",
    "    # On somme sur tous les éléments sauf les indices des filtres\n",
    "    #db = np.sum(dout, axis=(0, 2, 3))\n",
    "    # Initialisations\n",
    "    #dx = np.zeros_like(x)\n",
    "    dw = np.zeros((N,F,F,C,HH,WW,H_,W_),dtype=np.float32)\n",
    "    #db = np.zeros_like(b)\n",
    "    \n",
    "    # dw = xp * dy\n",
    "    # 0-padding juste sur les deux dernières dimensions de x\n",
    "    xp = np.pad(x, ((0,), (0,), (pad,), (pad, )), 'constant')\n",
    "    # Version sans vectorisation\n",
    "    for n in range(N):\n",
    "        for f in range(F):#\n",
    "            for i in range(HH): # \n",
    "                for j in range(WW):\n",
    "                    for k in range(H_): # \n",
    "                        for l in range(W_):\n",
    "                            for c in range(C): # \n",
    "                                dw[n,f,f,c,i,j,k,l] += xp[n, c, stride*i+k, stride*j+l]\n",
    "                                \n",
    "    return dw #shape [datapoints, out_filters, in_channels, kernel_height, kernel_width, data_height, data_width]\n",
    "\n",
    "\n",
    "def calc_dx(x,w,b,pad,stride,H_,W_):\n",
    "    '''\n",
    "    calculates the derivative of conv(x,w) with respect to x\n",
    "    \n",
    "    output is a nd-array of shape n x ch_in x og_h x og_w x (h_out w_out ch_out)\n",
    "    '''\n",
    "    dx, dw, db = None, None, None\n",
    "\n",
    "    # Récupération des variables\n",
    "    #x, w, b, conv_param = cache\n",
    "    #pad = conv_param['pad']\n",
    "    #stride = conv_param['stride']\n",
    "    \n",
    "    # Dimensions\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape #F_out, C_in, kernel_height, kernel_width\n",
    "    #_, _, H_, W_ = dout.shape\n",
    "    \n",
    "    # db - dout (N, F, H', W')\n",
    "    # On somme sur tous les éléments sauf les indices des filtres\n",
    "    #db = np.sum(dout, axis=(0, 2, 3))\n",
    "    # Initialisations\n",
    "    #dx = np.zeros_like(x)\n",
    "    dx = np.zeros((N,C,H,W,F,H_,W_,),dtype=np.float32)\n",
    "    #db = np.zeros_like(b)\n",
    "    \n",
    "    # dw = xp * dy\n",
    "    # 0-padding juste sur les deux dernières dimensions de x\n",
    "    xp = np.pad(x, ((0,), (0,), (pad,), (pad, )), 'constant')\n",
    "    for n in range(N):\n",
    "        for f in range(F):#\n",
    "            for i in range(H): # \n",
    "                for j in range(W):\n",
    "                    for k in range(H_): # \n",
    "                        for l in range(W_):\n",
    "                            for c in range(C): # \n",
    "                                dx[n,c,i,j,f,k,l] += w[f, c, stride*i-k, stride*j-l]\n",
    "                                #dx[0,0,0,0,0,0,0,0] = w[0,0,0,0]\n",
    "                                #dx[0,0,1,0,0,0,0,0] = w[0,0,1,0]\n",
    "                                #dx[0,0,1,0,0,0,1,0] = w[0,0,0,0]\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "374c33aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(X,normalize=False):\n",
    "    X = F.relu(X)\n",
    "    if normalize:\n",
    "        return np.sqrt(2*np.pi/(np.pi-1))*(X-1/np.sqrt(2*np.pi))\n",
    "    else:\n",
    "        return X\n",
    "    \n",
    "\n",
    "# #Identity\n",
    "# def activation(x):\n",
    "#     return x\n",
    "\n",
    "# @njit\n",
    "# def d_activation(x):\n",
    "#     return np.ones(np.shape(x),dtype=np.float32) \n",
    "\n",
    "\n",
    "# #Tanh\n",
    "def activation(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "@njit\n",
    "def d_activation(x):\n",
    "    return np.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "478cd032",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8dd2243e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4bbef856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Easy NTK expects one output alone\n",
    "class dumb_small(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(2,3,3,bias=False)\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(3,3,3,bias=False)\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(1*3,1,bias=False)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = x_2.reshape(-1,1*3)\n",
    "        x_4 = self.d3(x_3)\n",
    "        return x_4\n",
    "    \n",
    "# Easy NTK expects one output alone\n",
    "class dumb_small_layerwise(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small_layerwise, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(2,3,3,bias=False)\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(3,3,3,bias=False)\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(1*3,1,bias=False)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = x_2.reshape(-1,1*3)\n",
    "        x_4 = self.d3(x_3)\n",
    "        return x_4, x_3, x_2, x_1, x_0\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c1e57f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 2, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([1, 3])\n",
      "torch.Size([3, 2, 3, 3])\n",
      "torch.Size([3, 3, 3, 3])\n",
      "torch.Size([1, 3])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cpu'\n",
    "\n",
    "model_small = dumb_small()\n",
    "model_small.to(device)\n",
    "model_small.apply(NTK_weights)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cpu'\n",
    "\n",
    "model_layerwise = dumb_small_layerwise()\n",
    "model_layerwise.to(device)\n",
    "model_layerwise.apply(NTK_weights)\n",
    "\n",
    "x_test = np.random.normal(0,1,(3,2,5,5)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "52116a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert torch.all(model_layerwise.d1.weight == model_small.d1.weight)\n",
    "assert torch.all(model_layerwise.d2.weight == model_small.d2.weight)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e7c321",
   "metadata": {},
   "source": [
    "# Easy_NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c13dfb34",
   "metadata": {},
   "outputs": [],
   "source": [
    "NTK_easy = calculate_NTK(model_small,x_test).detach().numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14fa16a2",
   "metadata": {},
   "source": [
    "# Pytorch Autograd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4332263c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_small.zero_grad()\n",
    "y = model_small(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "edc96e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#this method agrees between model layerwise and model small; meaning that the calculation is indepdent of those\n",
    "#two models. the insinuation is somehting is wrong with both my methods for calculating,--- the same thing, since\n",
    "#they agree with one another.\n",
    "\n",
    "#in the future we would iterate over layers instead of like this...\n",
    "layer_components_w1 = [] \n",
    "layer_components_w2 = []\n",
    "layer_components_w3 = []\n",
    "\n",
    "for output in y:\n",
    "    model_small.zero_grad()\n",
    "    \n",
    "    output.backward(retain_graph=True)\n",
    "\n",
    "    #Get the tensors\n",
    "    w1_grad = model_small.d1.weight.grad.detach().numpy()\n",
    "    w2_grad = model_small.d2.weight.grad.detach().numpy()\n",
    "    w3_grad = model_small.d3.weight.grad.detach().numpy()\n",
    "\n",
    "    #reshape and append. deep copy neccessary or else they are the same objects\n",
    "    layer_components_w1.append(w1_grad.reshape(-1).copy())\n",
    "    layer_components_w2.append(w2_grad.reshape(-1).copy())\n",
    "    layer_components_w3.append(w3_grad.reshape(-1).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "02228206",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_components_w1 = np.array(layer_components_w1)\n",
    "layer_components_w2 = np.array(layer_components_w2)\n",
    "layer_components_w3 = np.array(layer_components_w3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8df36c48",
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd_NTK = layer_components_w1 @ layer_components_w1.T+\\\n",
    "    layer_components_w2 @ layer_components_w2.T+\\\n",
    "    layer_components_w3 @ layer_components_w3.T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af204d12",
   "metadata": {},
   "source": [
    "# Layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cdf5bc77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_4, x_3, x_2, x_1, x_0 = model_layerwise(x_test)\n",
    "\n",
    "#Dense Weight Matrices\n",
    "Ws = []\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer reshape is a layer\n",
    "Ws.append(np.array([0.0],dtype=np.float32)) #spacer reshape is a layer\n",
    "Ws.append(model_layerwise.d3.weight.detach().numpy().astype(np.float32))\n",
    "\n",
    "\n",
    "#Kernel Matrices\n",
    "Ks = []\n",
    "Ks.append(model_layerwise.d1.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(model_layerwise.d2.weight.detach().numpy().astype(np.float32))\n",
    "Ks.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "Ks.append(np.array([0.0],dtype=np.float32)) #spacer\n",
    "\n",
    "Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "Xs.append(x_0.detach().numpy().T.astype(np.float32))\n",
    "Xs.append(x_1.detach().numpy().T.astype(np.float32))\n",
    "Xs.append(x_2.detach().numpy().T.astype(np.float32))\n",
    "Xs.append(x_3.detach().numpy().T.astype(np.float32))\n",
    "\n",
    "# Bs = []\n",
    "# Bs.append(model_layerwise.d1.bias.detach().numpy().astype(np.float32)[:,None])\n",
    "# Bs.append(model_layerwise.d2.bias.detach().numpy().astype(np.float32)[:,None])\n",
    "# Bs.append(model_layerwise.d3.bias.detach().numpy().astype(np.float32)[:,None])\n",
    "\n",
    "#This is used to create arrays-- needs to be integer list to play nice with compilers\n",
    "ds_int = []\n",
    "ds_int.append(0)\n",
    "ds_int.append(3*3*3) #channels_out * kernel_height * kernel_width???\n",
    "ds_int.append(3*3*3) #channels_out * kernel_height * kernel_width???\n",
    "ds_int.append(1) #reshape\n",
    "\n",
    "ds_array = [] #this is for the NTK formulation, \n",
    "ds_array.append(np.array([0.0],dtype=np.float32)) #first element is a spacer, could be anything.\n",
    "ds_array.append(np.array([1.0],dtype=np.float32)) #The rest, even if you dont use NTK formulation, would be 1\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))\n",
    "ds_array.append(np.array([1.0],dtype=np.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "72c9df19",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_C1 = Conv2d(model_layerwise.d1.weight.detach().numpy())\n",
    "pytorch_C2 = Conv2d(model_layerwise.d2.weight.detach().numpy())\n",
    "#pytorch_C1.forward(Xs[0].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "b5e03a40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.5320631 ,  0.29268035, -0.98313105]], dtype=float32)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Ws[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "d6d240ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#@njit #no parallel transformation available ;#fasterer\n",
    "def cross(X):\n",
    "    return X.T.dot(X)\n",
    "\n",
    "#I will need to know the order of the layers\n",
    "\n",
    "#Since the Dense layers depend on everything in front of them, unlikely that the Dense layer's derivatives change;\n",
    "#However, that would be different in arbitrary architectures where dense layers might be sprinkled in other than\n",
    "#the head.\n",
    "\n",
    "#At first lets just hardcode this, then we will try to generalize to LeNets afterwords\n",
    "def compute_NTK_CNN(Ws, Ks, Xs, d_int, d_array):\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "   \n",
    "    n = Xs[0].shape[1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    dws = []\n",
    "    dxs = []\n",
    "    ####################################################################################################\n",
    "    for l in range(0,L):\n",
    "        if np.all(Ws[l]!=0):\n",
    "            print('one of these cant be zero')\n",
    "            Ds_dense.append(d_activation(np.dot(Ws[l],Xs[l])))\n",
    "        else:\n",
    "            Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "    ####################################################################################################\n",
    "    for l in range(0,L):\n",
    "        if np.all(Ks[l]!=0): \n",
    "            Ds_conv.append( rearrange(d_activation(Conv2d(Ks[l]).forward(Xs[l].T)),'n f h w -> n (f h w)').T )\n",
    "        else:\n",
    "            Ds_conv.append(np.array([[0.0]],dtype=np.float32))\n",
    "    ####################################################################################################        \n",
    "    for l in range(0,L):\n",
    "        #!!! will need to be updated with strides, padding...\n",
    "        if np.all(Ks[l]!=0):\n",
    "            #dw2 = calc_dw(x=Xs[1].T,w=Ks[1],b=0,pad=0,stride=1,H_=Xs[2].shape[1],W_=Xs[2].shape[0])\n",
    "            dw = calc_dw(x=Xs[l].T,w=Ks[l],b=0,pad=0,stride=1,H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "            dws.append(rearrange(dw,'n f1 f2 c kh kw dh dw -> n (c f1 kh kw) (f2 dh dw)') )\n",
    "            if l != 0:\n",
    "                #dx2 = calc_dx(x=Xs[1].T,w=Ks[1],b=0,pad=0,stride=1,H_=Xs[2].shape[1],W_=Xs[2].shape[0])\n",
    "                dx = calc_dx(x=Xs[l].T,w=Ks[l],b=0,pad=0,stride=1,H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                dxs.append(rearrange(dx,'n c ih iw f oh ow -> n (c ih iw) (f oh ow)') )\n",
    "            else:\n",
    "                dxs.append(np.array([[0.0]],dtype=np.float32))\n",
    "        else:\n",
    "            dws.append(np.array([[0.0]],dtype=np.float32))\n",
    "            dxs.append(np.array([[0.0]],dtype=np.float32))\n",
    "    ####################################################################################################\n",
    "    #The first term is just conjugate kernel\n",
    "    KNTK = cross(Xs[L])\n",
    "    components.append(cross(Xs[L]))\n",
    "    \n",
    "    ###################################################################################################\n",
    "    for l in range(1,L+1):#l counts layers going forward from 1...\n",
    "        #we are going to construct terms that look like ( S^T S ) * (X^T X)\n",
    "        \n",
    "        #Skip over non Dense Layers, This could be made more rigorous, maybe pass named parameters?\n",
    "        if len(np.shape(Xs[l-1]))>2:\n",
    "            continue\n",
    "            \n",
    "        XtX = cross(Xs[l-1])\n",
    "        S = np.expand_dims(Ws[-1].T.reshape(-1)/np.sqrt(d_array[L]),axis=1) #has shape input to last layer.\n",
    "        for k in range(L,l-1,-1): #counts backwards from l\n",
    "            S = Ds_dense[k]*S\n",
    "            if k > l:\n",
    "                S = np.dot(S.T,Ws[k-1]).T/np.sqrt(d_array[k-1])\n",
    "        components.append(cross(S) * XtX)\n",
    "        KNTK += cross(S) * XtX\n",
    "    ####################################################################################################\n",
    "    for l in range(1,L+1):\n",
    "        #Skip over non CNN layers. This could be made more rigorous, but for LeNets it should work\n",
    "        if len(np.shape(Xs[l]))<=2:\n",
    "            continue\n",
    "        #Need to count backwards the Dense layers, since the algorithm is different... \n",
    "        S = Ws[-1].T / np.sqrt(d_array[L])\n",
    "        for k in range(L,l-1,-1):\n",
    "            if len(np.shape(Xs[k-1]))<=2: #\"if k is a dense layer\"\n",
    "                S = S*Ds_dense[k]\n",
    "                if k > l and not(np.all(Ws[k-1])==0):\n",
    "                    S = np.dot(S.T,Ws[k-1]).T/np.sqrt(d_array[k-1])\n",
    "            if len(np.shape(Xs[k-1]))>2: #and this is \"if k is a conv layer\"\n",
    "                S = S * Ds_conv[k-1]\n",
    "                if k-1 > l:\n",
    "                    S = dxs[k-2] @ S #this index probably is either one less, or the list is set up funky.\n",
    "                if k-1 == l:\n",
    "                    S = dws[k-2] @ S\n",
    "                    break\n",
    "        S = np.diagonal(S,0,2,0)\n",
    "        components.append(cross(S))\n",
    "        KNTK += cross(S)\n",
    "            \n",
    "    return KNTK, components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "87c0eb15",
   "metadata": {},
   "outputs": [],
   "source": [
    "layerwise_NTK, components = compute_NTK_CNN(Ws, Ks, Xs, ds_int, ds_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "c15e3a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 2.361841  , -0.6238191 ,  1.5283434 ],\n",
       "        [-0.6238191 ,  1.3279012 ,  0.35824418],\n",
       "        [ 1.5283434 ,  0.35824418,  1.9568596 ]], dtype=float32),\n",
       " array([[21.410667 ,  1.9315369,  1.7122195],\n",
       "        [ 1.9315369, 38.626312 , -0.6789525],\n",
       "        [ 1.7122195, -0.6789525,  5.5564547]], dtype=float32),\n",
       " array([[21.073723  ,  4.231202  ,  0.3355749 ],\n",
       "        [ 4.231202  , 56.42448   ,  0.41291073],\n",
       "        [ 0.3355749 ,  0.41291073,  2.0249605 ]], dtype=float32)]"
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "components"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d86c224",
   "metadata": {},
   "source": [
    "### Conv layer d2-- works"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "b24cc2ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 3, 3, 3, 1, 1)"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw1 = calc_dw(x=Xs[1].T,w=Ks[1],b=0,pad=0,stride=1,H_=Xs[2].shape[1],W_=Xs[2].shape[0])\n",
    "dw1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "7374cab2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 81, 3)\n"
     ]
    }
   ],
   "source": [
    "#i, j are the kernel height and width\n",
    "#k, l are the output data height and width\n",
    "dw1 = rearrange(dw1,'n f1 f2 c kh kw dh dw -> n (c f1 kh kw) (f2 dh dw)')\n",
    "#dw now gives dy(x_n)/dw_i,j,\n",
    "print(dw1.shape)\n",
    "#Need to reduce over the last axis in some way.\n",
    "#dw = np.sum(dw[:,:,:,::1],axis=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "dbeb90d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n"
     ]
    }
   ],
   "source": [
    "D_conv1 = d_activation(pytorch_C2.forward(Xs[1].T))\n",
    "D_conv1 = rearrange(D_conv1,'n f h w -> n (f h w)').T\n",
    "print(D_conv1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "c04027b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = np.diagonal((dw1) @ (Ws[3].T * D_conv1),0,2,0).T "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "64fd1a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "convolutional_components=[]\n",
    "convolutional_components.append(idk.dot(idk.T))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b88b1e57",
   "metadata": {},
   "source": [
    "### Conv layer d1--?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "ec59903a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 54, 27)"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw0 = calc_dw(x=Xs[0].T,w=Ks[0],b=0,pad=0,stride=1,H_=Xs[1].shape[1],W_=Xs[1].shape[0])\n",
    "dw0 = rearrange(dw0,'n f1 f2 c kh kw dh dw -> n (c f1 kh kw) (f2 dh dw)')\n",
    "#d(conv)/dw has shape n x number_of_weights x number_of_outputs\n",
    "dw0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "b32bbd5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3)"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_conv0 = d_activation(pytorch_C1.forward(Xs[0].T))\n",
    "D_conv0 = rearrange(D_conv0,'n f h w -> n (f h w)').T\n",
    "D_conv0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "87845a8e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3, 3, 3)"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xs[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "7b4f501e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 27, 3)\n"
     ]
    }
   ],
   "source": [
    "dx1 = calc_dx(x=Xs[1].T,w=Ks[1],b=0,pad=0,stride=1,H_=Xs[2].shape[1],W_=Xs[2].shape[0])\n",
    "dx1 = rearrange(dx1,'n c ih iw f oh ow -> n (c ih iw) (f oh ow)')\n",
    "#dx1 has shape n x input_number x number_of_outputs\n",
    "print(dx1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "1a542dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "idk = np.diagonal((dw0 @ (( (dx1) @ (Ws[3].T * D_conv1) ) * D_conv0)),0,2,0).T\n",
    "convolutional_components.append(idk.dot(idk.T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "id": "778b270d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_conv1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "1ffb2bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 3)"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(Ws[3].T * D_conv1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "465197d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 27, 3)"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dx1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "f413bb8b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 3)"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D_conv0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "c4d2ea2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 54, 27)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dw0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "dce8a128",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 54)"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idk.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "c3ef5e5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Pseudo Code:\n",
    "\n",
    "# for layer in convolutional_layers:\n",
    "#     S = Ws[-1].T\n",
    "#     for l in convolutional_layers[convolutional_layers > layer]:\n",
    "#         S = S * D_conv[l]\n",
    "#         if l > layer:\n",
    "#             S = dx[l] @ S\n",
    "#         if l == layer:\n",
    "#             S = dw[l] @ S\n",
    "            \n",
    "#     S = np.diagonal(S,0,2,0)\n",
    "#     component = S.T.dot(S)\n",
    "\n",
    "\n",
    "\n",
    "#This requires extra computation:, each should change with each iteration.\n",
    "\n",
    "#dw, a list of d_conv[layer] / dw\n",
    "\n",
    "#dx, a list of d_conv[layer] / dx\n",
    "\n",
    "#D_conv, a list of d/d(Conv[layer](X[layer])) (sigma(Conv[layer](X[layer])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "7b9e4dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#NTK_layerwise = components[0] + convolutional_components[0] + convolutional_components[1]\n",
    "NTK_layerwise = components[0] + components[1] + components[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1465fcc6",
   "metadata": {},
   "source": [
    "# Compare Against One another"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "185cec87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4846230e+01, 5.5389199e+00, 3.5761378e+00],\n",
       "       [5.5389199e+00, 9.6378693e+01, 9.2202395e-02],\n",
       "       [3.5761378e+00, 9.2202395e-02, 9.5382748e+00]], dtype=float32)"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK_layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "8fb7fc71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4846222e+01, 5.5389180e+00, 3.5761366e+00],\n",
       "       [5.5389194e+00, 9.6378632e+01, 9.2202753e-02],\n",
       "       [3.5761366e+00, 9.2202872e-02, 9.5382767e+00]], dtype=float32)"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK_easy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "82286a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4.4846230e+01, 5.5389175e+00, 3.5761366e+00],\n",
       "       [5.5389175e+00, 9.6378624e+01, 9.2203021e-02],\n",
       "       [3.5761366e+00, 9.2203021e-02, 9.5382767e+00]], dtype=float32)"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd_NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "76046bfa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.allclose(NTK_layerwise,NTK_easy))\n",
    "print(np.allclose(NTK_layerwise,autograd_NTK))\n",
    "print(np.allclose(NTK_easy,autograd_NTK))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6270825e",
   "metadata": {},
   "source": [
    "# Compare Layerwise Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "824ca5ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[21.410646   1.9315356  1.7122178]\n",
      " [ 1.9315356 38.626266  -0.6789523]\n",
      " [ 1.7122178 -0.6789523  5.5564556]]\n",
      "[[21.073744    4.231201    0.33557537]\n",
      " [ 4.231201   56.42445     0.41291112]\n",
      " [ 0.33557537  0.41291112  2.0249615 ]]\n",
      "[[ 2.361841   -0.6238191   1.5283434 ]\n",
      " [-0.6238191   1.3279012   0.35824418]\n",
      " [ 1.5283434   0.35824418  1.9568596 ]]\n"
     ]
    }
   ],
   "source": [
    "print(layer_components_w1 @ layer_components_w1.T)\n",
    "print(layer_components_w2 @ layer_components_w2.T)\n",
    "print(layer_components_w3 @ layer_components_w3.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0a04fd17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[0. 0. 0.]\n",
      " [0. 0. 0.]\n",
      " [0. 0. 0.]]\n",
      "[[ 2.361841   -0.6238191   1.5283434 ]\n",
      " [-0.6238191   1.3279012   0.35824418]\n",
      " [ 1.5283434   0.35824418  1.9568596 ]]\n"
     ]
    }
   ],
   "source": [
    "print(components[1])\n",
    "print(components[2])\n",
    "print(components[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
