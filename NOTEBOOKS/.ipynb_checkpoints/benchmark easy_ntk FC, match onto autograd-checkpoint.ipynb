{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dac4b389",
   "metadata": {},
   "source": [
    "# This notebook first demonstrates the basic principle behind our method through autograd, then uses analytic derivatives to find the ntk in parallel\n",
    "\n",
    "# the point is that for simple architectures the autograd NTK agrees with the analytic method up to a rtol typically of 1e-2 , visually inspecting shows that elements are very close.\n",
    "\n",
    "# We can also use this notebook to benchmark the FC ntk-- though note the expected time for autograd NTK to finish for large network or networks with many points is also large, consider skipping these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a703448",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from layerwise_ntk import compute_NTK_CNN\n",
    "import numpy as np\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d44cb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from easy_ntk import compute_NTK_CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07c5caeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#a = torch.tensor([0.0])\n",
    "#a = a.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "774508f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "how_many = 100_000\n",
    "width = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1659e5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def activation(x):\n",
    "#     return torch.tanh(x)\n",
    "\n",
    "\n",
    "# @njit\n",
    "# def d_activation(x):\n",
    "#     return np.cosh(x)**-2\n",
    "\n",
    "def d_activationt(x):\n",
    "    return torch.cosh(x)**-2\n",
    "\n",
    "def activation(x):\n",
    "    return torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dded7b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "188869b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dumb_small(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(784,width,bias=True) #28 -> 28\n",
    "\n",
    "        self.d2 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d4 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d5 = torch.nn.Linear(width,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = self.d5(x_4)\n",
    "        return x_5\n",
    "\n",
    "class dumb_small_layerwise(torch.nn.Module):\n",
    "    '''\n",
    "    simple network for test cases\n",
    "    \n",
    "    \n",
    "    It seems like bias vectors aren't trivially added.\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small_layerwise, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Linear(784,width,bias=True) #28 -> 28\n",
    "\n",
    "        self.d2 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d3 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d4 = torch.nn.Linear(width,width,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d5 = torch.nn.Linear(width,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = self.d5(x_4)\n",
    "        return x_5, x_4, x_3, x_2, x_1, x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d39fc4e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 784])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([1, 100])\n",
      "torch.Size([100, 784])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([100, 100])\n",
      "torch.Size([1, 100])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cpu'\n",
    "\n",
    "model = dumb_small_layerwise()\n",
    "model.apply(NTK_weights)\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model_2 = dumb_small()\n",
    "model_2.apply(NTK_weights)\n",
    "\n",
    "x_test = np.random.normal(0,1,(how_many,784)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36c4ad99",
   "metadata": {},
   "source": [
    "# Autograd NTK-- uncomment and run if number used and width are small, like both under 100, in order to test that the result and the result of the easy_ntk layerwise algorithm agree with oneanother. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a125b267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_2.zero_grad()\n",
    "# y = model_2(x_test)\n",
    "\n",
    "# #in the future we would iterate over layers instead of like this...\n",
    "# layer_components_w1 = [] \n",
    "# layer_components_w2 = []\n",
    "# layer_components_w3 = []\n",
    "# layer_components_w4 = []\n",
    "# layer_components_w5 = []\n",
    "\n",
    "# layer_components_b1 = []\n",
    "# layer_components_b2 = []\n",
    "# layer_components_b3 = []\n",
    "# layer_components_b4 = []\n",
    "# layer_components_b5 = []\n",
    "\n",
    "# for i in range(len(y)):\n",
    "#     model_2.zero_grad()\n",
    "#     y[i].backward(retain_graph=True)\n",
    "#     #Get the tensors\n",
    "#     w1_grad = model_2.d1.weight.grad.detach().numpy()\n",
    "#     w2_grad = model_2.d2.weight.grad.detach().numpy()\n",
    "#     w3_grad = model_2.d3.weight.grad.detach().numpy()\n",
    "#     w4_grad = model_2.d4.weight.grad.detach().numpy()\n",
    "#     w5_grad = model_2.d5.weight.grad.detach().numpy()\n",
    "    \n",
    "#     b1_grad = model_2.d1.bias.grad.detach().numpy()\n",
    "#     b2_grad = model_2.d2.bias.grad.detach().numpy()\n",
    "#     b3_grad = model_2.d3.bias.grad.detach().numpy()\n",
    "#     b4_grad = model_2.d4.bias.grad.detach().numpy()\n",
    "#     b5_grad = model_2.d5.bias.grad.detach().numpy()\n",
    "\n",
    "#     #reshape and append. deep copy neccessary or else they are the same objects\n",
    "#     layer_components_w1.append(w1_grad.reshape(-1).copy())\n",
    "#     layer_components_w2.append(w2_grad.reshape(-1).copy())\n",
    "#     layer_components_w3.append(w3_grad.reshape(-1).copy())\n",
    "#     layer_components_w4.append(w4_grad.reshape(-1).copy())\n",
    "#     layer_components_w5.append(w5_grad.reshape(-1).copy())\n",
    "    \n",
    "#     layer_components_b1.append(b1_grad.reshape(-1).copy())\n",
    "#     layer_components_b2.append(b2_grad.reshape(-1).copy())\n",
    "#     layer_components_b3.append(b3_grad.reshape(-1).copy())\n",
    "#     layer_components_b4.append(b4_grad.reshape(-1).copy())\n",
    "#     layer_components_b5.append(b5_grad.reshape(-1).copy())\n",
    "\n",
    "# layer_components_w1 = np.array(layer_components_w1)\n",
    "# layer_components_w2 = np.array(layer_components_w2)\n",
    "# layer_components_w3 = np.array(layer_components_w3)\n",
    "# layer_components_w4 = np.array(layer_components_w4)\n",
    "# layer_components_w5 = np.array(layer_components_w5)\n",
    "\n",
    "# layer_components_b1 = np.array(layer_components_b1)\n",
    "# layer_components_b2 = np.array(layer_components_b2)\n",
    "# layer_components_b3 = np.array(layer_components_b3)\n",
    "# layer_components_b4 = np.array(layer_components_b4)\n",
    "# layer_components_b5 = np.array(layer_components_b5)\n",
    "\n",
    "# autograd_NTK = layer_components_w1 @ layer_components_w1.T+\\\n",
    "#     layer_components_w2 @ layer_components_w2.T+\\\n",
    "#     layer_components_w3 @ layer_components_w3.T+\\\n",
    "#     layer_components_w4 @ layer_components_w4.T+\\\n",
    "#     layer_components_w5 @ layer_components_w5.T+\\\n",
    "#     layer_components_b1 @ layer_components_b1.T+\\\n",
    "#     layer_components_b2 @ layer_components_b2.T+\\\n",
    "#     layer_components_b3 @ layer_components_b3.T+\\\n",
    "#     layer_components_b4 @ layer_components_b4.T+\\\n",
    "#     layer_components_b5 @ layer_components_b5.T\n",
    "\n",
    "# autograd_NTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d77907a0",
   "metadata": {},
   "source": [
    "# easy NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e5d26f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.to('cpu')\n",
    "x_5, x_4, x_3, x_2, x_1, x_0 = model(x_test)\n",
    "\n",
    "#These need to be numpy\n",
    "Ws = []\n",
    "Ws.append(model.d1.weight.detach())\n",
    "Ws.append(model.d2.weight.detach())\n",
    "Ws.append(model.d3.weight.detach())\n",
    "Ws.append(model.d4.weight.detach())\n",
    "Ws.append(model.d5.weight.detach())\n",
    "\n",
    "#Kernel Matrices, Need to be numpy\n",
    "Ks = []\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32)) \n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "\n",
    "\n",
    "Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "Xs.append(x_0.T.detach())\n",
    "Xs.append(x_1.T.detach())\n",
    "Xs.append(x_2.T.detach())\n",
    "Xs.append(x_3.T.detach())\n",
    "Xs.append(x_4.T.detach())\n",
    "\n",
    "#This is used to create arrays-- needs to be integer list to play nice with compilers\n",
    "ds_int = []\n",
    "ds_int.append(1)\n",
    "ds_int.append(1)\n",
    "ds_int.append(1)\n",
    "ds_int.append(1)\n",
    "ds_int.append(1)\n",
    "\n",
    "ds_array = [] #this is for the NTK formulation, \n",
    "#ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #first element is a spacer, could be anything.\n",
    "\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) \n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) \n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "\n",
    "filters = []\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "\n",
    "\n",
    "padding = []\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "\n",
    "\n",
    "strides = []\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "\n",
    "\n",
    "\n",
    "layers=[model.d1,\n",
    "        model.d2,\n",
    "        model.d3,\n",
    "        model.d4,\n",
    "        model.d5\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "04fa9409",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at CPUAllocator.cpp:67] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 40000000000 bytes. Error code 12 (Cannot allocate memory)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_20963/3023719382.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mnow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mntk_components\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_NTK_CNN\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mWs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mKs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mXs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_int\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mds_array\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstrides\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0md_activationt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20963/2594237322.py\u001b[0m in \u001b[0;36mcompute_NTK_CNN\u001b[0;34m(Ws, Ks, Xs, d_int, d_array, strides, padding, layers, d_activationt, device)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mL\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayers\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m                 \u001b[0mcomponents\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcross_pt_nonp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mcross_pt_nonp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mXs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0md_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mW\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mones\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md_int\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_20963/1443504459.py\u001b[0m in \u001b[0;36mcross_pt_nonp\u001b[0;34m(X, device)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_pt_nonp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mcross_pt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at CPUAllocator.cpp:67] . DefaultCPUAllocator: can't allocate memory: you tried to allocate 40000000000 bytes. Error code 12 (Cannot allocate memory)"
     ]
    }
   ],
   "source": [
    "now = time.time()\n",
    "ntk_components = compute_NTK_CNN(Ws, Ks, Xs, ds_int, ds_array, strides, padding, layers, d_activationt, device=\"cpu\")\n",
    "print(time.time() - now)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "eb2239f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.45 ms ± 2.37 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "ntk_components = compute_NTK_CNN(Ws, Ks, Xs, ds_int, ds_array, strides, padding, layers, d_activationt, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2a37a7eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "NTK = torch.sum(torch.stack(ntk_components),[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49bbefd9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.allclose((layer_components_w4 @ layer_components_w4.T),ntk_components[2].cpu().numpy(),1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3ed0ecad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.3095946 ,  0.11968824,  1.1234529 , ...,  2.032055  ,\n",
       "         0.55126   ,  1.4060948 ],\n",
       "       [ 0.11968824,  3.210734  ,  0.16980146, ...,  1.8690039 ,\n",
       "         0.02743362,  0.8184704 ],\n",
       "       [ 1.1234529 ,  0.16980146,  2.0710466 , ...,  0.13769273,\n",
       "         0.22619286,  0.1258586 ],\n",
       "       ...,\n",
       "       [ 2.032055  ,  1.8690039 ,  0.13769273, ..., 12.222395  ,\n",
       "         4.1873646 ,  0.6115483 ],\n",
       "       [ 0.55126   ,  0.02743362,  0.22619286, ...,  4.1873646 ,\n",
       "        10.260793  ,  1.1471453 ],\n",
       "       [ 1.4060948 ,  0.8184704 ,  0.1258586 , ...,  0.6115483 ,\n",
       "         1.1471453 ,  3.4726658 ]], dtype=float32)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = layer_components_b4 @ layer_components_b4.T\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a15734a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 6.309475  ,  0.11969332,  1.1234163 , ...,  2.0322046 ,\n",
       "         0.55130553,  1.4061674 ],\n",
       "       [ 0.11969332,  3.2107909 ,  0.16979226, ...,  1.8690201 ,\n",
       "         0.02743386,  0.81847763],\n",
       "       [ 1.1234163 ,  0.16979226,  2.071053  , ...,  0.13768236,\n",
       "         0.22619265,  0.12585686],\n",
       "       ...,\n",
       "       [ 2.0322046 ,  1.8690201 ,  0.13768236, ..., 12.222448  ,\n",
       "         4.187412  ,  0.61153996],\n",
       "       [ 0.55130553,  0.02743386,  0.22619265, ...,  4.187412  ,\n",
       "        10.260914  ,  1.1472785 ],\n",
       "       [ 1.4061674 ,  0.81847763,  0.12585686, ...,  0.61153996,\n",
       "         1.1472785 ,  3.4728098 ]], dtype=float32)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = ntk_components[3].cpu().numpy()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "eaa23e37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isclose(a,b,1e-2)) / np.prod(np.shape(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "b735c0a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9988"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(np.isclose(NTK.cpu().numpy(),autograd_NTK,1e-1)) / np.prod(np.shape(NTK))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
