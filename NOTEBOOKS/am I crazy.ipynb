{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6df6a079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from layerwise_ntk import compute_NTK_CNN\n",
    "import numpy as np\n",
    "import random\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch import load\n",
    "from torch.nn import functional as F\n",
    "from torch import autograd\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import time\n",
    "\n",
    "from numba import njit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d0642c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 1\n",
    "how_many = 10\n",
    "width = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2d91067d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def activation(x):\n",
    "    return torch.tanh(x)\n",
    "\n",
    "def d_activationt(x):\n",
    "    return torch.cosh(x)**-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9761aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def NTK_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]\n",
    "    if isinstance(m, nn.Conv2d):\n",
    "        print(m.weight.shape)\n",
    "        nn.init.normal_(m.weight.data)#/m.weight.shape[0]\n",
    "        if m.bias != None:\n",
    "            nn.init.normal_(m.bias.data)#/m.weight.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "826e7b9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dumb_small(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(1,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d3 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d4 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d5 = torch.nn.Linear(width*28*28,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = x_4.reshape(how_many,-1)\n",
    "        x_6 = self.d5(x_5)\n",
    "        return x_6 \n",
    "\n",
    "class dumb_small_layerwise(torch.nn.Module):\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    def __init__(self,):\n",
    "        super(dumb_small_layerwise, self).__init__()\n",
    "        \n",
    "        self.d1 = torch.nn.Conv2d(1,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "\n",
    "        self.d2 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d3 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d4 = torch.nn.Conv2d(width,width,3,stride=1,padding=1,bias=True) #28 -> 28\n",
    "        \n",
    "        self.d5 = torch.nn.Linear(width*28*28,1,bias=True)\n",
    "        \n",
    "    def forward(self, x_0):\n",
    "        x_1 = activation(self.d1(x_0))\n",
    "        x_2 = activation(self.d2(x_1))\n",
    "        x_3 = activation(self.d3(x_2))\n",
    "        x_4 = activation(self.d4(x_3))\n",
    "        x_5 = x_4.reshape(how_many,-1)\n",
    "        x_6 = self.d5(x_5)\n",
    "        return x_6, x_5, x_4, x_3, x_2, x_1, x_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "4963e24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([1, 1568])\n",
      "torch.Size([2, 1, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([2, 2, 3, 3])\n",
      "torch.Size([1, 1568])\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "device='cuda'\n",
    "\n",
    "model = dumb_small_layerwise()\n",
    "model.apply(NTK_weights)\n",
    "model.to(device)\n",
    "\n",
    "torch.manual_seed(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "\n",
    "model_2 = dumb_small()\n",
    "model_2.apply(NTK_weights)\n",
    "\n",
    "x_test = np.random.normal(0,1,(how_many,1,28,28)).astype(np.float32) #n c_in, h, w\n",
    "x_test = torch.from_numpy(x_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c073613f",
   "metadata": {},
   "source": [
    "# autograd NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "f5bb1bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = model_2(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9195d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "#in the future we would iterate over layers instead of like this...\n",
    "layer_components_w1 = [] \n",
    "layer_components_w2 = []\n",
    "layer_components_w3 = []\n",
    "layer_components_w4 = []\n",
    "layer_components_w5 = []\n",
    "\n",
    "layer_components_b1 = []\n",
    "layer_components_b2 = []\n",
    "layer_components_b3 = []\n",
    "layer_components_b4 = []\n",
    "layer_components_b5 = []\n",
    "\n",
    "for i in range(len(y)):\n",
    "    model_2.zero_grad()\n",
    "    y[i].backward(retain_graph=True)\n",
    "    #Get the tensors\n",
    "    w1_grad = model_2.d1.weight.grad.detach().numpy()\n",
    "    w2_grad = model_2.d2.weight.grad.detach().numpy()\n",
    "    w3_grad = model_2.d3.weight.grad.detach().numpy()\n",
    "    w4_grad = model_2.d4.weight.grad.detach().numpy()\n",
    "    w5_grad = model_2.d5.weight.grad.detach().numpy()\n",
    "    \n",
    "    b1_grad = model_2.d1.bias.grad.detach().numpy()\n",
    "    b2_grad = model_2.d2.bias.grad.detach().numpy()\n",
    "    b3_grad = model_2.d3.bias.grad.detach().numpy()\n",
    "    b4_grad = model_2.d4.bias.grad.detach().numpy()\n",
    "    b5_grad = model_2.d5.bias.grad.detach().numpy()\n",
    "\n",
    "    #reshape and append. deep copy neccessary or else they are the same objects\n",
    "    layer_components_w1.append(w1_grad.reshape(-1).copy())\n",
    "    layer_components_w2.append(w2_grad.reshape(-1).copy())\n",
    "    layer_components_w3.append(w3_grad.reshape(-1).copy())\n",
    "    layer_components_w4.append(w4_grad.reshape(-1).copy())\n",
    "    layer_components_w5.append(w5_grad.reshape(-1).copy())\n",
    "    \n",
    "    layer_components_b1.append(b1_grad.reshape(-1).copy())\n",
    "    layer_components_b2.append(b2_grad.reshape(-1).copy())\n",
    "    layer_components_b3.append(b3_grad.reshape(-1).copy())\n",
    "    layer_components_b4.append(b4_grad.reshape(-1).copy())\n",
    "    layer_components_b5.append(b5_grad.reshape(-1).copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb2e5b75",
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_components_w1 = np.array(layer_components_w1)\n",
    "layer_components_w2 = np.array(layer_components_w2)\n",
    "layer_components_w3 = np.array(layer_components_w3)\n",
    "layer_components_w4 = np.array(layer_components_w4)\n",
    "layer_components_w5 = np.array(layer_components_w5)\n",
    "\n",
    "layer_components_b1 = np.array(layer_components_b1)\n",
    "layer_components_b2 = np.array(layer_components_b2)\n",
    "layer_components_b3 = np.array(layer_components_b3)\n",
    "layer_components_b4 = np.array(layer_components_b4)\n",
    "layer_components_b5 = np.array(layer_components_b5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "8aa376d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "autograd_NTK = layer_components_w1 @ layer_components_w1.T+\\\n",
    "    layer_components_w2 @ layer_components_w2.T+\\\n",
    "    layer_components_w3 @ layer_components_w3.T+\\\n",
    "    layer_components_w4 @ layer_components_w4.T+\\\n",
    "    layer_components_w5 @ layer_components_w5.T+\\\n",
    "    layer_components_b1 @ layer_components_b1.T+\\\n",
    "    layer_components_b2 @ layer_components_b2.T+\\\n",
    "    layer_components_b3 @ layer_components_b3.T+\\\n",
    "    layer_components_b4 @ layer_components_b4.T+\\\n",
    "    layer_components_b5 @ layer_components_b5.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "400e1e50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59836.47  ,   3977.612 ,   7510.154 ,   5900.3413,  -9817.224 ,\n",
       "         -8714.666 ,  11040.326 ,   6799.4146,   6449.1904,  -8002.1436],\n",
       "       [  3977.612 ,  55491.45  , -11823.79  ,  10096.725 ,  -1672.399 ,\n",
       "         -7544.5215, -15084.612 ,   1674.8015,  -8772.489 ,  -2589.3086],\n",
       "       [  7510.154 , -11823.79  ,  48860.906 , -11370.099 ,  -1974.4307,\n",
       "         -4039.8022,   9705.948 ,  -3303.679 ,   8632.894 ,  -9849.061 ],\n",
       "       [  5900.3413,  10096.725 , -11370.099 ,  52536.566 ,   5125.1304,\n",
       "          1728.0623,   4379.146 ,  10997.768 ,  -7178.7183,   3225.5261],\n",
       "       [ -9817.224 ,  -1672.399 ,  -1974.4307,   5125.1304,  48201.19  ,\n",
       "         -6298.4385,  -7977.8916,  -6658.238 ,  -8914.406 ,   5350.665 ],\n",
       "       [ -8714.666 ,  -7544.5215,  -4039.8022,   1728.0623,  -6298.4385,\n",
       "         42243.957 ,   2231.7742,  15565.518 , -13035.078 , -11552.813 ],\n",
       "       [ 11040.326 , -15084.612 ,   9705.948 ,   4379.146 ,  -7977.8916,\n",
       "          2231.7742,  54164.723 ,    809.9006,   8367.0625,  -8313.113 ],\n",
       "       [  6799.4146,   1674.8015,  -3303.679 ,  10997.768 ,  -6658.238 ,\n",
       "         15565.518 ,    809.9006,  70000.984 ,  -1031.1577,   5135.1636],\n",
       "       [  6449.1904,  -8772.489 ,   8632.894 ,  -7178.7183,  -8914.406 ,\n",
       "        -13035.078 ,   8367.0625,  -1031.1577,  64464.984 , -21467.771 ],\n",
       "       [ -8002.1436,  -2589.3086,  -9849.061 ,   3225.5261,   5350.665 ,\n",
       "        -11552.813 ,  -8313.113 ,   5135.1636, -21467.771 ,  79442.695 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd_NTK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a4f03a",
   "metadata": {},
   "source": [
    "# Now Layerwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eacb68bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = x_test.to('cuda')\n",
    "x_6, x_5, x_4, x_3, x_2, x_1, x_0 = model(x_test)\n",
    "\n",
    "#These need to be numpy\n",
    "Ws = []\n",
    "Ws.append(torch.tensor([0.0],dtype=torch.float32)) \n",
    "Ws.append(torch.tensor([0.0],dtype=torch.float32)) \n",
    "Ws.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "Ws.append(torch.tensor([0.0],dtype=torch.float32)) #spacer\n",
    "Ws.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "Ws.append(model.d5.weight.detach())\n",
    "\n",
    "#Kernel Matrices, Need to be numpy\n",
    "Ks = []\n",
    "Ks.append(model.d1.weight.detach())\n",
    "Ks.append(model.d2.weight.detach())\n",
    "Ks.append(model.d3.weight.detach())\n",
    "Ks.append(model.d4.weight.detach())\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32)) #spacer\n",
    "Ks.append(torch.tensor([0.0],dtype=torch.float32))\n",
    "\n",
    "\n",
    "Xs = [] # Xs are shape (output x #DP) ; however, typical python notation is reversed, so we take transpose here\n",
    "Xs.append(x_0.T.detach())\n",
    "Xs.append(x_1.T.detach())\n",
    "Xs.append(x_2.T.detach())\n",
    "Xs.append(x_3.T.detach())\n",
    "Xs.append(x_4.T.detach())\n",
    "Xs.append(x_5.T.detach())\n",
    "\n",
    "#This is used to create arrays-- needs to be integer list to play nice with compilers\n",
    "ds_int = []\n",
    "ds_int.append(width*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(width*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(width*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(width*3*3) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "ds_int.append(1) #channels_out * kernel_height * kernel_width\n",
    "\n",
    "ds_array = [] #this is for the NTK formulation, \n",
    "#ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #first element is a spacer, could be anything.\n",
    "\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #first element is a spacer, could be anything.\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device)) #The rest, even if you dont use NTK formulation, would be 1\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "ds_array.append(torch.tensor([1.0],dtype=torch.float32).to(device))\n",
    "\n",
    "filters = []\n",
    "filters.append(1)\n",
    "filters.append(1)\n",
    "filters.append(1)\n",
    "filters.append(1)\n",
    "filters.append(0)\n",
    "filters.append(0)\n",
    "\n",
    "\n",
    "padding = []\n",
    "padding.append(1)\n",
    "padding.append(1)\n",
    "padding.append(1)\n",
    "padding.append(1)\n",
    "padding.append(0)\n",
    "padding.append(0)\n",
    "\n",
    "\n",
    "strides = []\n",
    "strides.append(1)\n",
    "strides.append(1)\n",
    "strides.append(1)\n",
    "strides.append(1)\n",
    "strides.append(0)\n",
    "strides.append(0)\n",
    "\n",
    "\n",
    "layers=[model.d1,\n",
    "        model.d2,\n",
    "        model.d3,\n",
    "        model.d4,\n",
    "        0.0,\n",
    "        model.d5\n",
    "       ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "55e781bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@njit\n",
    "def calc_dw(x,w,b,pad,stride,H_,W_):\n",
    "    \"\"\"\n",
    "    Calculates the derivative of conv(x,w) with respect to w\n",
    "    \n",
    "    output is shape:\n",
    "        [datapoints, in_channels out_filters, kernel_height, kernel_width, out_filters, data_height, data_width\n",
    "    \n",
    "    'n f1 f2 c kh kw dh dw -> n (c f1 kh kw) (f2 dh dw)'\n",
    "    \"\"\"\n",
    "    dx, dw, db = None, None, None\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape\n",
    "    \n",
    "    #dw = np.zeros((N,F,F,C,HH,WW,H_,W_),dtype=np.float32)\n",
    "    \n",
    "    dw = np.zeros((N,C,F,HH,WW,F,H_,W_),dtype=np.float32)\n",
    "\n",
    "    xp = zero_pad(x,pad)\n",
    "    #high priority, how to vectorize this operation?\n",
    "    for n in range(N):\n",
    "        for f in range(F):\n",
    "            for i in range(HH): \n",
    "                for j in range(WW): \n",
    "                    for k in range(H_): \n",
    "                        for l in range(W_): \n",
    "                            for c in range(C): \n",
    "                                dw[n,c,f,i,j,f,k,l] += xp[n, c, i+stride*k, j+stride*l]                             \n",
    "    \n",
    "    return dw.reshape((N,(C*F*HH*WW),(F*H_*W_)))\n",
    "\n",
    "@njit\n",
    "def calc_dx(x,w,b,pad,stride,H_,W_):\n",
    "    '''\n",
    "    calculates the derivative of conv(x,w) with respect to x\n",
    "    \n",
    "    output is a nd-array of shape n x ch_in x og_h x og_w x (h_out w_out ch_out)\n",
    "    '''\n",
    "    dx, dw, db = None, None, None\n",
    "    N, C, H, W = x.shape\n",
    "    F, _, HH, WW = w.shape \n",
    "\n",
    "    dx = np.zeros((C,H,W,F,H_,W_,),dtype=np.float32)\n",
    "    #high priority, how to vectorize this operation? maybe with np.chunk,split?\n",
    "    for f in range(F): \n",
    "        for i in range(H): \n",
    "            for j in range(W):\n",
    "                for k in range(H_): \n",
    "                    for l in range(W_):\n",
    "                        for c in range(C): \n",
    "                            if i-stride*k+pad > HH-1 or j-stride*l+pad > WW-1:\n",
    "                                continue #this is alternative to padding w with zeros.\n",
    "                            if i-stride*k+pad < 0 or j-stride*l+pad < 0:\n",
    "                                continue #this is alternative to padding w with zeros.\n",
    "                            dx[c,i,j,f,k,l] += w[f, c, i-stride*k+pad, j-stride*l+pad]\n",
    "    #'c ih iw f oh ow -> (c ih iw) (f oh ow)'\n",
    "    return dx.reshape(((C*H*W),(F*H_*W_)))\n",
    "    \n",
    "@njit\n",
    "def zero_pad(A,pad):\n",
    "    N, F, H, W = A.shape\n",
    "    P = np.zeros((N, F, H+2*pad, W+2*pad),dtype=np.float32)\n",
    "    P[:,:,pad:H+pad,pad:W+pad] = A\n",
    "    return P\n",
    "    \n",
    "@njit\n",
    "def cross(X):\n",
    "    return X.T.dot(X)\n",
    "\n",
    "def cross_pt_nonp(X,device='cuda'):\n",
    "    X = X.to(device)\n",
    "    return X.T.matmul(X)\n",
    "\n",
    "def cross_pt(X,device='cuda'):\n",
    "    X = torch.from_numpy(X).to(device)\n",
    "    X = X.to(device)\n",
    "    return X.T.matmul(X).cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c90842ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_NTK_CNN(Ws: list, Ks: list, Xs: list, d_int: list, d_array: list, strides: list, padding: list, layers: list, d_activationt, device=\"cuda\", ) -> list:\n",
    "    '''\n",
    "    MAIN:\n",
    "    \n",
    "    Inputs: \n",
    "    Ws: list, has length number of layers + any reshaping, contains dense layer weight tensors, detatched, and on device\n",
    "    Ks: list, has length number of layers + any reshaping, contains 2d convolutional layers weight tensors, detatched, and on device\n",
    "    Xs: list, has length number of layers + any reshaping, contains all intermediate outputs of each layer in the models\n",
    "    d_int: list, has the number of bias parameters in each dense layer in the models\n",
    "    d_array: list, has the value of which to sqrt and divide by in each layer, typically called the NTK normalization. else, its values are 1.\n",
    "    strides: list, has the value of stride in each convolutional layer, else 0\n",
    "    padding: list, has the value of padding in each convolutional layer, else 0\n",
    "    layers: list, is a list containing the pytorch layers in the model, and \"0\" as a placeholder for a reshaping layer\n",
    "    device: str, one of either 'cpu' or 'cuda'; must be the same as the model device location\n",
    "    \n",
    "    NOTE: all of the above lists should have the same length! See example\n",
    "    \n",
    "    OUTPUTS: list of torch.tensor objects, each the ntk 'component' for that layer. Given in backwards order, i.e. starting with the last layer. First weight, then bias.\n",
    "    \n",
    "    NOTE: to get the full ntk, simply sum over the layer dimension of the result: NTK = torch.sum(torch.stack(components),dim=(0))\n",
    "    '''\n",
    "    components = []\n",
    "    \n",
    "    L = len(Xs)-1 #number of layers, Xs goes from inputs to right before outputs; X_0 is the input, X_L CK\n",
    "    n = Xs[0].shape[-1] #number of datapoints\n",
    "\n",
    "    #holds the derivatives of activation, first value is empty list...?; just a spacer, replace with array\n",
    "    Ds_dense = [np.array([[0.0]],dtype=np.float32)] \n",
    "    Ds_conv = [np.array([[0.0]],dtype=np.float32)]\n",
    "    s_matrices = []\n",
    "    with torch.no_grad():\n",
    "        ####################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Linear):\n",
    "                Ds_dense.append(d_activationt(layers[l](Xs[l].T)).T)\n",
    "            else:\n",
    "                Ds_dense.append(np.array([[0.0]],dtype=np.float32))\n",
    "        ################################################################################################\n",
    "        for l in range(0,L):\n",
    "            if isinstance(layers[l],torch.nn.Conv2d):\n",
    "                Ds_conv.append(d_activationt(layers[l](Xs[l].T)).reshape(n,-1).T)\n",
    "            else:\n",
    "                Ds_conv.append(np.array([[0.0]],dtype=np.float32))      \n",
    "        ####################################################################################################\n",
    "        S = torch.tensor([1.0],dtype=torch.float32).to(device) #this models the backward propogation:   \n",
    "        for l in range(L,-1,-1):\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "\n",
    "                components.append(cross_pt_nonp(S,device)*cross_pt_nonp(Xs[l],device)/d_array[l])\n",
    "\n",
    "                W = torch.ones((d_int[l],n),dtype=torch.float32).to(device) * S\n",
    "                components.append(cross_pt_nonp(W,device).to(device)/d_array[l])\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                if len(S.shape) == 2: #this should only affect the very last layer, at which point, who cares.\n",
    "                    S = S[None,:,:]\n",
    "                    \n",
    "                dw = calc_dw(x=Xs[l].T.cpu().numpy(),w=Ks[l].cpu().numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                \n",
    "                W = torch.matmul(torch.from_numpy(dw).to(device),S.to(device))\n",
    "                \n",
    "                #We should bring this to zhichao or sombody and ask if there is obviously something faster?\n",
    "                #W = np.diagonal(W,0,2,0)\n",
    "                W = torch.diagonal(W,0,0,2)\n",
    "\n",
    "                components.append(cross_pt_nonp(W,device).to(device)/d_array[l])\n",
    "\n",
    "                N = Ks[l].shape[0]\n",
    "                W = np.split(S.cpu().numpy(),N,axis=1)\n",
    "                #W = torch.split(S,N,dim=1)\n",
    "                \n",
    "                W = np.array(W)\n",
    "                #W = torch.stack(W)\n",
    "                \n",
    "                W = np.sum(W,axis=(1,2))\n",
    "                #W = torch.sum(W,dim=(1,2))\n",
    "                \n",
    "                components.append(torch.from_numpy(cross(W,)).to(device)/d_array[l])\n",
    "                #components.append(cross_pt_nonp(W,device))\n",
    "\n",
    "            #############################\n",
    "            #now we setup S for the next loop by treating appropriately\n",
    "            if l==0:\n",
    "                break\n",
    "\n",
    "            if isinstance(layers[l], torch.nn.Linear):\n",
    "                S = torch.matmul(S.T,Ws[l]).T / torch.sqrt(d_array[l])\n",
    "                if len(S.shape) < 2:\n",
    "                    S = S[:,None] #expand dimension along axis 1\n",
    "                if not(isinstance(layers[l-1],float)): #this exludes the reshaping layer\n",
    "                    S = Ds_dense[l]*S\n",
    "                else: #and when the reshaping layer occurs we need to apply this instead\n",
    "                    S = Ds_conv[l-1]*S\n",
    "\n",
    "            elif isinstance(layers[l], torch.nn.Conv2d):\n",
    "                dx = calc_dx(x=Xs[l].T.cpu().numpy(),w=Ks[l].cpu().numpy(),b=0,pad=padding[l],stride=strides[l],H_=Xs[l+1].shape[1],W_=Xs[l+1].shape[0])\n",
    "                S = (torch.from_numpy(dx[None,:,:]).to(device) @ S) / torch.sqrt(d_array[l])\n",
    "                S = Ds_conv[l]*S\n",
    "            \n",
    "    return components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "408c8f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntk_components = compute_NTK_CNN(Ws, Ks, Xs, ds_int, ds_array, strides, padding, layers, d_activationt, device=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "45606db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "NTK = torch.sum(torch.stack(ntk_components),[0,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c96e0c14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 59836.4453,   3977.6206,   7510.1577,   5900.3535,  -9817.2129,\n",
       "          -8714.6875,  11040.3232,   6799.4028,   6449.2119,  -8002.1455],\n",
       "        [  3977.6206,  55491.4609, -11823.7842,  10096.6865,  -1672.3936,\n",
       "          -7544.5234, -15084.6240,   1674.8302,  -8772.4531,  -2589.3267],\n",
       "        [  7510.1577, -11823.7842,  48860.9297, -11370.1064,  -1974.4534,\n",
       "          -4039.8328,   9705.9492,  -3303.6462,   8632.8955,  -9849.0312],\n",
       "        [  5900.3535,  10096.6865, -11370.1064,  52536.5469,   5125.1240,\n",
       "           1728.0475,   4379.1343,  10997.7793,  -7178.6963,   3225.5466],\n",
       "        [ -9817.2129,  -1672.3936,  -1974.4534,   5125.1240,  48201.2070,\n",
       "          -6298.4243,  -7977.9150,  -6658.2529,  -8914.4473,   5350.6494],\n",
       "        [ -8714.6875,  -7544.5234,  -4039.8328,   1728.0475,  -6298.4243,\n",
       "          42243.9883,   2231.7571,  15565.5020, -13035.1094, -11552.8125],\n",
       "        [ 11040.3232, -15084.6240,   9705.9492,   4379.1343,  -7977.9150,\n",
       "           2231.7571,  54164.7070,    809.8851,   8367.0742,  -8313.1465],\n",
       "        [  6799.4028,   1674.8302,  -3303.6462,  10997.7793,  -6658.2529,\n",
       "          15565.5020,    809.8851,  70001.0156,  -1031.1260,   5135.1943],\n",
       "        [  6449.2119,  -8772.4531,   8632.8955,  -7178.6963,  -8914.4473,\n",
       "         -13035.1094,   8367.0742,  -1031.1260,  64465.0391, -21467.8027],\n",
       "        [ -8002.1455,  -2589.3267,  -9849.0312,   3225.5466,   5350.6494,\n",
       "         -11552.8125,  -8313.1465,   5135.1943, -21467.8027,  79442.7656]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f228c105",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 59836.47  ,   3977.612 ,   7510.154 ,   5900.3413,  -9817.224 ,\n",
       "         -8714.666 ,  11040.326 ,   6799.4146,   6449.1904,  -8002.1436],\n",
       "       [  3977.612 ,  55491.45  , -11823.79  ,  10096.725 ,  -1672.399 ,\n",
       "         -7544.5215, -15084.612 ,   1674.8015,  -8772.489 ,  -2589.3086],\n",
       "       [  7510.154 , -11823.79  ,  48860.906 , -11370.099 ,  -1974.4307,\n",
       "         -4039.8022,   9705.948 ,  -3303.679 ,   8632.894 ,  -9849.061 ],\n",
       "       [  5900.3413,  10096.725 , -11370.099 ,  52536.566 ,   5125.1304,\n",
       "          1728.0623,   4379.146 ,  10997.768 ,  -7178.7183,   3225.5261],\n",
       "       [ -9817.224 ,  -1672.399 ,  -1974.4307,   5125.1304,  48201.19  ,\n",
       "         -6298.4385,  -7977.8916,  -6658.238 ,  -8914.406 ,   5350.665 ],\n",
       "       [ -8714.666 ,  -7544.5215,  -4039.8022,   1728.0623,  -6298.4385,\n",
       "         42243.957 ,   2231.7742,  15565.518 , -13035.078 , -11552.813 ],\n",
       "       [ 11040.326 , -15084.612 ,   9705.948 ,   4379.146 ,  -7977.8916,\n",
       "          2231.7742,  54164.723 ,    809.9006,   8367.0625,  -8313.113 ],\n",
       "       [  6799.4146,   1674.8015,  -3303.679 ,  10997.768 ,  -6658.238 ,\n",
       "         15565.518 ,    809.9006,  70000.984 ,  -1031.1577,   5135.1636],\n",
       "       [  6449.1904,  -8772.489 ,   8632.894 ,  -7178.7183,  -8914.406 ,\n",
       "        -13035.078 ,   8367.0625,  -1031.1577,  64464.984 , -21467.771 ],\n",
       "       [ -8002.1436,  -2589.3086,  -9849.061 ,   3225.5261,   5350.665 ,\n",
       "        -11552.813 ,  -8313.113 ,   5135.1636, -21467.771 ,  79442.695 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "autograd_NTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "18a5838d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(np.all(np.isclose(autograd_NTK,NTK.cpu(),1e-4)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
